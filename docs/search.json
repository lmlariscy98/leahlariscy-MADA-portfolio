[
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Introduction\nThis is the TidyTuesday data set for February 14th, 2023. Data consist of observations pertaining to age differences in couples from Hollywood movies spanning almost an entire century.\n\n\nLoading packages and setting figure size\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(skimr)\nlibrary(ggpmisc)\n\nLoading required package: ggpp\n\nAttaching package: 'ggpp'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8) \n\n\n\nData loading\nFollow the TidyTuesday instructions for 2023-02-14\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nData exploration\n\nskim(age_gaps)\n\n\nData summary\n\n\nName\nage_gaps\n\n\nNumber of rows\n1155\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmovie_name\n0\n1\n2\n43\n0\n830\n0\n\n\ndirector\n0\n1\n3\n31\n0\n510\n0\n\n\nactor_1_name\n0\n1\n6\n22\n0\n567\n0\n\n\nactor_2_name\n0\n1\n7\n27\n0\n647\n0\n\n\ncharacter_1_gender\n0\n1\n3\n5\n0\n2\n0\n\n\ncharacter_2_gender\n0\n1\n3\n5\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nactor_1_birthdate\n0\n1\n1889-04-16\n1996-06-01\n1964-10-03\n562\n\n\nactor_2_birthdate\n0\n1\n1906-10-06\n1996-11-11\n1974-07-30\n640\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n0\n1\n2000.80\n16.37\n1935\n1997\n2004\n2012\n2022\n▁▁▁▆▇\n\n\nage_difference\n0\n1\n10.42\n8.51\n0\n4\n8\n15\n52\n▇▃▂▁▁\n\n\ncouple_number\n0\n1\n1.40\n0.75\n1\n1\n1\n2\n7\n▇▁▁▁▁\n\n\nactor_1_age\n0\n1\n40.64\n10.42\n18\n33\n39\n47\n81\n▂▇▅▂▁\n\n\nactor_2_age\n0\n1\n30.21\n7.50\n17\n25\n29\n34\n68\n▇▇▂▁▁\n\n\n\n\n\nBy using skim(), I can see many interesting things about the data:\n\nThe mean age difference between couples is about 10 years.\nThere are 830 unique movies listed, spanning from 1935 to 2022, with most movies only having one couple each.\nSome actor names are repeated upwards of 20 times, showing that they have been involved in multiple couples.\n\n\n\nIdeas for analysis\n\nI will start by designating sexuality of each couple into three groups (straight, gay, sapphic) because I am interested to see how many queer couples there are. If there are enough, we could look at age gap differences between each group.\nI will then determine which gender is the oldest in each pair because I hypothesize that men will be older more of the time.\nI will start with these two questions for now and see where they take me\n\n\n\nMutate data\n\nClassifying sexuality of each couple\nHere I will create a new variable called sexuality based on whether each couple is of same or opposite gender, creating three labels for these relationships: straight (man & woman), gay (man & man), and sapphic (woman & woman)\nI will also look at how many observations there are for each sexuality.\n\nage_gaps_sexuality <- age_gaps %>% \n  mutate(sexuality = case_when(character_1_gender == 'man' & character_2_gender == 'woman' ~ 'straight',\n                               character_1_gender == 'man' & character_2_gender == 'man' ~ 'gay',\n                               character_1_gender == 'woman' & character_2_gender == 'woman' ~ 'sapphic',\n                               character_2_gender == 'man' & character_1_gender == 'woman' ~ 'straight',\n                               character_2_gender == 'man' & character_1_gender == 'man' ~ 'gay',\n                               character_2_gender == 'woman' & character_1_gender == 'woman' ~ 'sapphic'))\nsexuality_count <- age_gaps_sexuality %>% count(sexuality)\nsexuality_count <- sexuality_count %>% mutate(proportion = n/sum(n))\ntibble(sexuality_count)\n\n# A tibble: 3 × 3\n  sexuality     n proportion\n  <chr>     <int>      <dbl>\n1 gay          12    0.0104 \n2 sapphic      11    0.00952\n3 straight   1132    0.980  \n\n\nHere, you see that 98% of couples in this data set can be defined as heterosexual.\n\n\nCounting how many times each gender is older than their partner\nHere, I will count the number of times each gender is older and then calculate that proportion.\n\nolder_count <- age_gaps %>% count(character_1_gender)\nolder_count <- older_count %>% mutate(proportion = n/sum(n))\ntibble(older_count)\n\n# A tibble: 2 × 3\n  character_1_gender     n proportion\n  <chr>              <int>      <dbl>\n1 man                  941      0.815\n2 woman                214      0.185\n\n\nAs you can see here, men in Hollywood are much more likely to be older than their partner than women are. In this data set, men were older than their partner 80% of the time.\n\n\n\nData visualization\n\nDifference in average age gaps between straight, gay, and sapphic couples\n\nage_gaps_sexuality %>% ggplot(aes(sexuality, age_difference, color = sexuality)) +\n  geom_boxplot() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nIt appears that gay couples have a higher average age gap than other sexualities, but remember that they make up only 1% of observations.\n\n\nNumber of same-movie couples throughout the years\n\nage_gaps_sexuality %>% ggplot(aes(y = couple_number, x = release_year, fill = sexuality)) + \n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(name = \"Year Released\", breaks = seq(1930,2022,10)) +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nOnly straight couples were documented in Hollywood prior to the 1990s. Queer couplings began to be documented in the 1990s and early 2000s, but still make up a small portion of couples which we saw earlier. We can also note that queer couplings started to pop up around the time that couple numbers in Hollywood dramatically increased in the late 1990s.\n\n\nDifference in age gaps between older men and women\n\nage_gaps %>% ggplot(aes(character_1_gender, age_difference, color = character_1_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, older men tend to have a higher age gap with their partner than older women do.\n\n\nDifference in age gaps between younger men and women\n\nage_gaps %>% ggplot(aes(character_2_gender, age_difference, color = character_2_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, younger men tend to have a smaller age gap with their partners compared to younger women who have a larger average age gap.\n\n\nLinear regression of age vs age gap between men and women\n\nage_gaps %>% ggplot(aes(actor_1_age, age_difference, color = character_1_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(name = \"Gender\", values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of older partner's age vs. relationship age gap\")\n\n\n\n\nMen in Hollywood who date younger people (most of them) are more likely to have an increased age gap in their relationships as they age, more so than women.\n\nage_gaps %>% ggplot(aes(actor_2_age, age_difference, color = character_2_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of younger parter's age vs. relationship age gap\")\n\n\n\n\nWe do not see this same trend with the younger partners. This makes sense partly because as someone gets older, there are going to be less people older than them and eventually they will have to be with someone their own age.\nThere are less men who are younger than their partner than men who are older, and there seems to be no indication that their age is a determining factor in their relationship age gap.\nThere are far more women who are younger than their partner than men, and overall it appears there are less women in couples past the age of 40, compared to the first scatter plot where men are in couples well past their 40s.\n\n\n\nDiscussion and conclusions\nWhat I learned from looking at this data of Hollywood couples on the same movie set:\n\n98% of documented couples were heterosexual\nMen (~80%) were more likely to date someone younger than them then women (20%) were\nOlder men had a higher average age gap in their relationships (10 years vs 2-3 years in women), meaning they were more likely to date women much younger than them than older women were to date much younger men\nOlder partners of both genders showed an increase in relationship age gaps as their own age increased, although this was much more pronounced for men, meaning that as these men aged, they continued to date young women\n\n\nFrom this data exploration, I have concluded that on average, men in Hollywood tend to date much younger women than themselves. They also continue to date much younger women as they age. I would also be interested in looking at the average age of all men recorded vs the average age of women because I have a feeling that men on average are older.\nTo conclude, and to quote Taylor Swift, “I’ll get older, but your lovers stay my age”."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "My name is Leah Lariscy and I have a BS in Environmental Health and am now a first year PhD student in Environmental Health. My advisers are Travis Glenn and Erin Lipp and my research involves molecular detection in wastewater, mainly viral pathogens such as SARS-CoV-2, Mpox, and RSV. I also have some experience in many microbiology techniques, as well as some bioinformatics."
  },
  {
    "objectID": "aboutme.html#experience",
    "href": "aboutme.html#experience",
    "title": "About me",
    "section": "Experience",
    "text": "Experience\nI first began working with R studio at the beginning of 2022, although I was mostly just trying to learn from other grad students and self-teach. In the Fall of 2022 I started my graduate career by taking EPID 7500, an intro to coding in R course, which allowed me to get familiar with R studio and get comfortable doing simple analysis. I also started running the wastewater surveillance script for the Lipp Lab’s COVID-19 surveillance website in the Fall. This involved raw data from qPCR outputs which I used to estimate copies per liter of SARS-CoV-2 viral particles in Athens-Clarke County wastewater influent."
  },
  {
    "objectID": "aboutme.html#my-goals-for-the-class",
    "href": "aboutme.html#my-goals-for-the-class",
    "title": "About me",
    "section": "My goals for the class",
    "text": "My goals for the class\nI have been looking forward to taking this class for a while now as I’ve heard so many great things! My hope is that this class will give me more tools to become a better researcher, such as creating reproducible workflows and doing more complicated statistical analysis on my own data."
  },
  {
    "objectID": "aboutme.html#a-picture-of-me",
    "href": "aboutme.html#a-picture-of-me",
    "title": "About me",
    "section": "A picture of me!",
    "text": "A picture of me!"
  },
  {
    "objectID": "aboutme.html#lipp-lab-covid-19-surveillance-website",
    "href": "aboutme.html#lipp-lab-covid-19-surveillance-website",
    "title": "About me",
    "section": "Lipp Lab COVID-19 Surveillance Website",
    "text": "Lipp Lab COVID-19 Surveillance Website\nCOVID-19 Dashboard\nHere is the surveillance site that I described above, which shows you a graph of wastewater viral levels compared to clinical cases of COVID-19 from July 2020 to December 2022. Since I only have experience working on the data analysis side of this, I am also interested in learning to create websites similar to this for my continued detection work with other pathogens."
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "Data is from the FiveThirtyEight article Inside The Political Donation History Of Wealthy Sports Owners\n\n\n\n\nlibrary(tidyverse) #for data cleaning\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here) #for setting file paths\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\nlibrary(ggthemes) #for loading ggplot themes\nlibrary(skimr) #for skimming data sets\n\n\n\n\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8) \n\n\n\n\nYou will see that the data set includes the following variables -> Owner,Team,League, Recipient, Amount, Election Year, and Party\n\nhere()\n\n[1] \"/Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\"\n\ndonation <- read_csv(\"data/sports-political-donations/sports-political-donations.csv\")\n\nRows: 2798 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Owner, Team, League, Recipient, Amount, Party\ndbl (1): Election Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nskim(donation)\n\n\nData summary\n\n\nName\ndonation\n\n\nNumber of rows\n2798\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nOwner\n0\n1\n9\n43\n0\n158\n0\n\n\nTeam\n0\n1\n9\n59\n0\n115\n0\n\n\nLeague\n0\n1\n3\n14\n0\n16\n0\n\n\nRecipient\n0\n1\n3\n96\n0\n1274\n0\n\n\nAmount\n0\n1\n3\n10\n0\n244\n0\n\n\nParty\n0\n1\n3\n33\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2017.93\n1.6\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇\n\n\n\n\n\n\n\n\nThese are the following steps I took to prepare the data.\n\nFilter for rows containing only the 6 leagues, leaving out ones that were cross-listed among many leagues. This removed a large amount of the data, meaning that a majority of team owners own multiple teams across various leagues.\nFilter for rows containing only democrat or republican, leaving out bipartisan donations. I would have left these in but I had issuing renaming all variations to just bipartisan.\nParse the numerical values from Amount so it can then act as a numerical.\nGroup by League, Election Year, and Party\nSum the Amount of each group to find the total dollar amount of donations from each of the 6 leagues to each of the two parties in a given year.\nUngroup. Data is now ready to plot.\n\n\ndonation_clean <- donation %>% \n  filter(League ==c(\"MLB\",\"NASCAR\",\"NBA\",\"NFL\",\"NHL\",\"WNBA\")) %>% \n \n  filter(Party ==c(\"Democrat\",\"Republican\")) %>% \n  \n  mutate(Amount = parse_number(Amount)) %>% \n  \n  group_by(League,`Election Year`,Party) %>% \n  \n  summarise(party_donations = sum(Amount)) %>% \n  \n  ungroup() \n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\")`.\nCaused by warning in `League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\")`:\n! longer object length is not a multiple of shorter object length\n\n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `Party == c(\"Democrat\", \"Republican\")`.\nCaused by warning in `Party == c(\"Democrat\", \"Republican\")`:\n! longer object length is not a multiple of shorter object length\n\n\n`summarise()` has grouped output by 'League', 'Election Year'. You can override\nusing the `.groups` argument.\n\nskim(donation_clean)\n\n\nData summary\n\n\nName\ndonation_clean\n\n\nNumber of rows\n32\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nLeague\n0\n1\n3\n6\n0\n6\n0\n\n\nParty\n0\n1\n8\n10\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2018.0\n1.68\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇\n\n\nparty_donations\n0\n1\n138422.2\n379996.99\n1600\n9250\n18450\n65300\n1808600\n▇▁▁▁▁\n\n\n\n\n\n\n\n\n\ndonation_plot <- donation_clean %>%\nggplot(aes(fill=Party, y=party_donations, x=`Election Year`)) +\n\n  geom_bar(position = \"fill\", stat = \"identity\", color = \"white\") + #basic geometry of plot, bar plot\n\n  facet_wrap(as.factor(donation_clean$League)) + #plot by individual League\n\n  scale_fill_manual(name=\"DONATIONS TO\", values=c(\"#00A5E3\", \"#CC0000\"), #looked up hexcodes on google \n  labels=c(\"DEMOCRATS\",\"REPUBLICANS\")) + #fill colors in correct order\n\n  theme_fivethirtyeight() + #theme from fivethirtyeight website\n\n  scale_x_continuous(breaks = seq(2016,2020,2)) + #2 year breaks between 2016 & 2020\n\n  labs(title = \"Across leagues, majority of donations go to Republicans\",\n  subtitle = \"Share of donations from team owners in six leagues, per year, league and party\") +\n\n  theme(legend.title = element_text(face = \"bold\", size = 16),\n  legend.text = element_text(size = 16),\n  plot.title.position = \"plot\",\n  plot.title = element_text(face = \"bold\", size = 24),\n  plot.subtitle = element_text(size = 18),\n  legend.position = \"top\",\n  axis.text.x = element_text(size = 14))\n  donation_plot\n\n\n\n\nYou will notice that the proportions on my plot are slightly different from the original. This is because I excluded all cross-listed league affiliations (for the sake of time, but in the future I would like to be able to parse these out into individual observations). I also excluded bipartisan donations and NAs because I was having trouble renaming these all to bipartisan. I would also like to work on this, as I would like to be able to re-create this chart more accurately.\nI also had some formatting issues that I couldn’t quite work out on my own. For one, I could not figure out how to change the size of the facet labels. I also struggled to find a way to change the y-axis tick labels to be percentages like on the original."
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "#load the dslabs package\n#install.packages(\"dslabs\")\nlibrary(dslabs)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n#look at help page for gapminder data\nhelp(\"gapminder\")\n\n\n#look at the structure of the data\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n\n\n#look at a summary of the data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n\n\n#check what type of object the data is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n\n\n\n\n\n#subset the data so there is only data from the African continent in a new data frame\nafricadata <- gapminder %>% filter(continent == \"Africa\")\n\n\n#look at the structure of the data\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n\n\n#look at a summary of the data\nsummary(africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n\n\n#further subset the African data by creating a data frame with only infant_mortality and Life_expectancy\nafricadata2 <- africadata %>% select(c(infant_mortality, life_expectancy))\n\n\n#look at the structure of the data\nstr(africadata2)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n\n\n#look at a summary of the data\nsummary(africadata2)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\n\n\n#subset the African data again, but this time including only population and life_expectancy\nafricadata3 <- africadata %>% select(c(population, life_expectancy))\n\n\n#look at the structure of the data\nstr(africadata3)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n\n\n#look at a summary of the data\nsummary(africadata3)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\n\n\n\n\n#Plot life expectancy as a function of infant mortality\nggplot(data = africadata2) +\n  geom_point(aes(x = infant_mortality, y = life_expectancy))\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n#Plot life expectancy as a function of log10(population)\nggplot(data = africadata3) +\n  geom_point(aes(x = log10(population), y = life_expectancy))\n\nWarning: Removed 51 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n#Find which years have missing data for infant_mortality\nafrica_NAs <- africadata %>% select(c(country, year, infant_mortality)) %>% \n  filter(is.na(infant_mortality))\nsummary(africa_NAs)\n\n              country         year      infant_mortality\n Equatorial Guinea: 23   Min.   :1960   Min.   : NA     \n Angola           : 19   1st Qu.:1963   1st Qu.: NA     \n Gabon            : 19   Median :1968   Median : NA     \n Djibouti         : 17   Mean   :1978   Mean   :NaN     \n Guinea-Bissau    : 17   3rd Qu.:1978   3rd Qu.: NA     \n South Africa     : 15   Max.   :2016   Max.   : NA     \n (Other)          :116                  NA's   :226     \n\n\n\n#Subset the African data to only include data from the year 2000\nafricadata2000 <- africadata %>% filter(year == 2000)\n\n\n#look at the structure of the data\nstr(africadata2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n\n\n#look at a summary of the data\nsummary(africadata2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n#Plot life expectancy as a function of infant mortality\nggplot(data = africadata2000) +\n  geom_point(aes(x = infant_mortality, y = life_expectancy))\n\n\n\n\n\n#Plot life expectancy as a function of log10(population)\nggplot(data = africadata2000) +\n  geom_point(aes(x = log10(population), y = life_expectancy))\n\n\n\n\n\n#Use a linear model, fit life expectancy as the outcome and infant mortality as the predictor\n#p-value is very small, infant mortality is very likely to predict life expectancy\nfit1 <- lm(infant_mortality ~ life_expectancy, data = africadata2000)\nsummary(fit1)\n\n\nCall:\nlm(formula = infant_mortality ~ life_expectancy, data = africadata2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-67.262  -9.806  -1.891  12.460  52.285 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     219.0135    21.4781  10.197 1.05e-13 ***\nlife_expectancy  -2.4854     0.3769  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.55 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\n\n\n#Use a linear model, fit life expectancy as the outcome and population as the predictor\n#p-value is large, population size is unlikley to predict life expectancy\nfit2 <- lm(population ~ life_expectancy, data = africadata2000)\nsummary(fit2)\n\n\nCall:\nlm(formula = population ~ life_expectancy, data = africadata2000)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-18308728 -12957963  -6425955   2079794 107435285 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)\n(Intercept)      5074933   21193712   0.239    0.812\nlife_expectancy   187799     371938   0.505    0.616\n\nResidual standard error: 22250000 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159"
  },
  {
    "objectID": "coding_exercise.html#this-section-added-by-sara-benist",
    "href": "coding_exercise.html#this-section-added-by-sara-benist",
    "title": "R Coding Exercise",
    "section": "This section added by Sara Benist",
    "text": "This section added by Sara Benist\n###Load the packages\n\nlibrary(dslabs)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(broom)\n\n\nSubsetting data\nI want to continue to explore the data related to African countries, specifically how gdp and infant mortality relates to fertility.\n\n#subset African countries\nafricadata <- filter(gapminder, continent == \"Africa\")\n\n#select only the `gdp` and `fertility` columns and assign to `gdpfert`\ngdpfert <- africadata %>% select(gdp, fertility)\n\n#select only the `fertility` and `infant_mortality` columns and assign to `fertmort`\nfertmort <- africadata %>% select(fertility, infant_mortality)\n\n\n\nPlotting the data\nNext, I wanted to look at the plots for the two new datasets. For both gdpfert and fertmort, I plotted the data points using geom_point() and geom_smooth() to produce a scatter plot with a smoothed line over the data. The smoothed line helps visualize patterns in the plot.\n\n#produce scatter plot with smooth line; x = gdp, y = fertility\n#x-axis log transformed for gdp data\nggplot(gdpfert, aes(gdp, fertility))+\n  geom_point() + \n  geom_smooth()+\n  scale_x_continuous(trans = \"log\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 637 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 637 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see a distinct negative correlation with fertility after the GDP of a country reaches above approx. 9.7 billion dollars. Note that most African countries have a GDP between 485 million and $9.7 billion dollars where the line fluctuates around 6 children per woman.\n\n#produce scatter plot with smooth line; x = fertility, y = infant_mortality\nggplot(fertmort, aes(fertility, infant_mortality)) +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 226 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\nHere, fertility and infant mortality are positively correlated until approximately 7 children per woman or 125 infants deaths per 1000.\n\n\nLinear modeling\nI would like to consider a linear model predicting fertility from GDP and infant mortality for African countries. The glm() function will be used to create a linear model for this scenario. The tidy() function from the broom package produces the summary of the model.\n\nfit3 <- glm(fertility ~ gdp + infant_mortality, data = africadata)\n\ntidy(fit3)\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)       3.91e+ 0  5.49e- 2      71.2 0        \n2 gdp              -1.41e-11  9.62e-13     -14.7 1.45e- 46\n3 infant_mortality  2.18e- 2  4.99e- 4      43.6 4.58e-300\n\n\nBoth GDP and infant mortality has a statistically significant affect on fertility (p-values > 0.001). GDP has an extremely small negative effect on fertility (slope = -1.411e-11), and infant mortality has a small positive effect (slope = 2.176e-2)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Leah Lariscy’s website and data analysis portfolio",
    "section": "",
    "text": "EPID 8060 (MADA)\n\nPlease use the Menu Bar above to look at completed exercises."
  },
  {
    "objectID": "data_analysis_exercise.html",
    "href": "data_analysis_exercise.html",
    "title": "Data Analysis Exercise",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(lubridate)"
  },
  {
    "objectID": "data_analysis_exercise.html#data-description",
    "href": "data_analysis_exercise.html#data-description",
    "title": "Data Analysis Exercise",
    "section": "Data description",
    "text": "Data description\nThis dataset was accessed from the Bacteria, Enterics, Amoeba, and Mycotics (BEAM) Dashboard, which houses data collected by the System for Enteric Disease Response, Investigation, and Coordination (SEDRIC). The data points represent pathogens isolated from infected individuals, namely Salmonella, E. Coli, Shigella, and Campylobacter bacteria.\nYou can access the BEAM Dashboard here.\n\nbeam_raw <- read_csv(\"data_analysis_exercise/data/raw_data/BEAM_Dashboard_Report_Data.csv\")\n\nRows: 128342 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): State, Source, Pathogen, Serotype/Species\ndbl (6): Year, Month, Number_of_isolates, Outbreak_associated_isolates, New_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "data_analysis_exercise.html#data-cleaning",
    "href": "data_analysis_exercise.html#data-cleaning",
    "title": "Data Analysis Exercise",
    "section": "Data cleaning",
    "text": "Data cleaning\nBegin by combining the Year and Month variables into one Date variable, then select for variables of interest and rename them. Lastly, change all NAs to 0s where necessary.\n\nbeam_clean <- beam_raw %>% mutate(date = make_date(year=Year, month=Month, day=1)) %>% \n\n  select(c(date, state=State, source=Source, pathogen=Pathogen, species=`Serotype/Species`,\n       n_isolates=Number_of_isolates, n_outbreak_associated=Outbreak_associated_isolates)) %>% \n\n  mutate(n_isolates = ifelse(is.na(n_isolates), 0, n_isolates), \n       n_outbreak_associated = ifelse(is.na(n_outbreak_associated), 0, n_outbreak_associated))\n\nprint(beam_clean)\n\n# A tibble: 128,342 × 7\n   date       state source pathogen    species                   n_iso…¹ n_out…²\n   <date>     <chr> <chr>  <chr>       <chr>                       <dbl>   <dbl>\n 1 2017-09-01 TX    Stool  Escherichia Shigella Flexneri Seroty…       1       0\n 2 2017-09-01 TX    Stool  Escherichia sonnei                         14       0\n 3 2017-09-01 TX    Stool  Salmonella  Agbeni                          1       0\n 4 2017-09-01 TX    Stool  Salmonella  Agona                           5       0\n 5 2017-09-01 TX    Stool  Salmonella  Altona                          1       0\n 6 2017-09-01 TX    Stool  Salmonella  Anatum                          2       2\n 7 2017-09-01 TX    Stool  Salmonella  Anatum, Newington, Minne…       2       0\n 8 2017-09-01 TX    Stool  Salmonella  Baildon                         1       0\n 9 2017-09-01 TX    Stool  Salmonella  Bareilly                        2       0\n10 2017-09-01 TX    Stool  Salmonella  Berta                           2       0\n# … with 128,332 more rows, and abbreviated variable names ¹​n_isolates,\n#   ²​n_outbreak_associated"
  },
  {
    "objectID": "data_analysis_exercise.html#save-cleaned-data-to-rds-file",
    "href": "data_analysis_exercise.html#save-cleaned-data-to-rds-file",
    "title": "Data Analysis Exercise",
    "section": "Save cleaned data to RDS file",
    "text": "Save cleaned data to RDS file\n\nsaveRDS(beam_clean, \"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#read-in-rds-file",
    "href": "data_analysis_exercise.html#read-in-rds-file",
    "title": "Data Analysis Exercise",
    "section": "Read in RDS file",
    "text": "Read in RDS file\n\n#read_rds(\"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#exploratory-analysis",
    "href": "data_analysis_exercise.html#exploratory-analysis",
    "title": "Data Analysis Exercise",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\nI would be interested in grouping by pathogen and exploring trends across states. I’d also like to see which pathogens are more likely to be associated with outbreaks."
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Penguins, meet Quarto!",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "hello.html#meet-the-penguins",
    "href": "hello.html#meet-the-penguins",
    "title": "Penguins, meet Quarto!",
    "section": "Meet the penguins",
    "text": "Meet the penguins\n\nThe penguins data from the palmerpenguins package contains size measurements for 344 penguins from three species observed on three islands in the Palmer Archipelago, Antarctica.\nThe plot below shows the relationship between flipper and bill lengths of these penguins."
  },
  {
    "objectID": "data_analysis_exercise.html#this-section-was-added-by-kimberly-perez",
    "href": "data_analysis_exercise.html#this-section-was-added-by-kimberly-perez",
    "title": "Data Analysis Exercise",
    "section": "This section was added by Kimberly Perez",
    "text": "This section was added by Kimberly Perez\n#Reading in RDS\nHere I will use the readRDS() function to load Leah’s cleaned BEAM data.\n\n#Utilize readRDS for this task\nnewbc<-readRDS(\"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#state-selection",
    "href": "data_analysis_exercise.html#state-selection",
    "title": "Data Analysis Exercise",
    "section": "State selection",
    "text": "State selection\nHere I will use the filter function to select seven states\n\nbc<- beam_clean %>%\n  filter(state == 'GA' | state == 'AZ' | state == 'CA'| state == 'ND' | state == 'NY'| state == 'OR' | state == 'KS')\n\n\nPathogen Source by State\n\nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")"
  },
  {
    "objectID": "data_analysis_exercise.html#outbreak-by-state-and-pathogen",
    "href": "data_analysis_exercise.html#outbreak-by-state-and-pathogen",
    "title": "Data Analysis Exercise",
    "section": "Outbreak by state and pathogen",
    "text": "Outbreak by state and pathogen\n\ntheme_set(theme_bw())  \nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022)\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "data_analysis_exercise.html#density-of-each-pathogen-over-time",
    "href": "data_analysis_exercise.html#density-of-each-pathogen-over-time",
    "title": "Data Analysis Exercise",
    "section": "Density of each pathogen over time",
    "text": "Density of each pathogen over time\nThis website seems to be a comprehensive resource for data visualization. I found the density plot and wanted to try my hand at recreating it. Below is my attempt.\n\nbcc <- ggplot(bc, aes(date))\nbcc + geom_density(aes(fill=factor(pathogen)), alpha=0.8) + \n    labs(title=\"Pathogen density from (2017-2022)\", \n         x=\"Year\",\n         y=\"Density\",\n         fill=\"Pathogen\") + ylim (0,0.001)"
  },
  {
    "objectID": "data_analysis_exercise.html#outbreak-by-state-and-pathogen-2017-2022",
    "href": "data_analysis_exercise.html#outbreak-by-state-and-pathogen-2017-2022",
    "title": "Data Analysis Exercise",
    "section": "Outbreak by State and Pathogen (2017-2022)",
    "text": "Outbreak by State and Pathogen (2017-2022)\n\ntheme_set(theme_bw())  \nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022) by State\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nbc_1<- bc %>% \n  group_by(date, pathogen, state, n_outbreak_associated) %>% \n  mutate(count=n()) %>% \n  ungroup() %>%  \n  select(-c(n_isolates, species, source))\n\nbc_1 %>% ggplot() +geom_line(\n  aes(x = date,\n      y = n_outbreak_associated,\n      color = pathogen,\n      linetype = state)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Number of Outbreaks (Associated with Pathogen)\",\n       color= \"Pathogen\",\n       linetype=\"State\",\n       title = \"Pathogen Associated with an Outbreak by State (2017-2022)\") +\n  theme(plot.title = element_text(hjust = 0.6))\n\n\n\n\nSalmonella and Ecoli look to be the pathogens that are associated with the largest number of outbreaks among these four states.\n\nPathogen Source by State\nHave you ever wondered what laboratories isolate pathogens from? Let’s explore the possibilities below!\n\n#Plotting \nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")\n\n\n\n\nFrom the visualization above, it looks like most labs are able to isolate pathogens from stool samples, however, there may be variation by state!"
  },
  {
    "objectID": "data_analysis_exercise.html#a-bit-more-data-wrangling",
    "href": "data_analysis_exercise.html#a-bit-more-data-wrangling",
    "title": "Data Analysis Exercise",
    "section": "A bit more data wrangling",
    "text": "A bit more data wrangling\nI will now select four states to analyze\n\n#Creating a new dataframe with four selected states\nbc<- newbc %>%\n  filter(state == 'GA'  | state == 'CA'| state == 'ND' | state == 'OR' )"
  },
  {
    "objectID": "data_analysis_exercise.html#potentially-helpful-resource",
    "href": "data_analysis_exercise.html#potentially-helpful-resource",
    "title": "Data Analysis Exercise",
    "section": "Potentially helpful resource",
    "text": "Potentially helpful resource\nThis website seems to be a helpful resource for data visualization. I found some interesting visualizations and hope to practice utilizing several."
  },
  {
    "objectID": "data_analysis_exercise.html#visualizing-outbreak-by-state-and-pathogen-2017-2022-in-two-ways",
    "href": "data_analysis_exercise.html#visualizing-outbreak-by-state-and-pathogen-2017-2022-in-two-ways",
    "title": "Data Analysis Exercise",
    "section": "Visualizing Outbreak by State and Pathogen (2017-2022) in two ways…",
    "text": "Visualizing Outbreak by State and Pathogen (2017-2022) in two ways…\n\ntheme_set(theme_bw())  \n\n#Visualizing the data...\nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022) by State\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n#Another way to visualize the data...\nbc %>% \n  ggplot() +geom_line(\n  aes(x = date,\n      y = n_outbreak_associated,\n      color = pathogen,\n      linetype = state)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Number of Outbreaks (Associated with Pathogen)\",\n       color= \"Pathogen\",\n       linetype=\"State\",\n       title = \"Pathogen Associated with an Outbreak by State (2017-2022)\") +\n  theme(plot.title = element_text(hjust = 0.6))\n\n\n\n\nSalmonella and Ecoli look to be the pathogens that are associated with the largest number of outbreaks among these four states.\n\nPathogen Source by State\nHave you ever wondered what laboratories isolate pathogens from? Let’s explore the possibilities below!\n\n#Plotting \nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")\n\n\n\n\nFrom the visualization above, it looks like most labs are able to isolate pathogens from stool samples, however, there may be variation by state!"
  },
  {
    "objectID": "visualization_exercise.html#load-data",
    "href": "visualization_exercise.html#load-data",
    "title": "Visualization Exercise",
    "section": "Load data",
    "text": "Load data\nYou will see that the data set includes the following variables -> Owner,Team,League, Recipient, Amount, Election Year, and Party\n\nhere()\n\n[1] \"/Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\"\n\ndonation <- read_csv(\"data/sports-political-donations/sports-political-donations.csv\")\n\nRows: 2798 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Owner, Team, League, Recipient, Amount, Party\ndbl (1): Election Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nskim(donation)\n\n\nData summary\n\n\nName\ndonation\n\n\nNumber of rows\n2798\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nOwner\n0\n1\n9\n43\n0\n158\n0\n\n\nTeam\n0\n1\n9\n59\n0\n115\n0\n\n\nLeague\n0\n1\n3\n14\n0\n16\n0\n\n\nRecipient\n0\n1\n3\n96\n0\n1274\n0\n\n\nAmount\n0\n1\n3\n10\n0\n244\n0\n\n\nParty\n0\n1\n3\n33\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2017.93\n1.6\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇"
  },
  {
    "objectID": "visualization_exercise.html#clean-and-wrangle-data",
    "href": "visualization_exercise.html#clean-and-wrangle-data",
    "title": "Visualization Exercise",
    "section": "Clean and wrangle data",
    "text": "Clean and wrangle data\nThese are the following steps I took to prepare the data.\n\nFilter for rows containing only the 6 leagues, leaving out ones that were cross-listed among many leagues. This removed a large amount of the data, meaning that a majority of team owners own multiple teams across various leagues.\nFilter for rows containing only democrat or republican, leaving out bipartisan donations. I would have left these in but I had issuing renaming all variations to just bipartisan.\nParse the numerical values from Amount so it can then act as a numerical.\nGroup by League, Election Year, and Party\nSum the Amount of each group to find the total dollar amount of donations from each of the 6 leagues to each of the two parties in a given year.\nUngroup. Data is now ready to plot.\n\n\ndonation_clean <- donation %>% \n  filter(League ==c(\"MLB\",\"NASCAR\",\"NBA\",\"NFL\",\"NHL\",\"WNBA\")) %>% \n \n  filter(Party ==c(\"Democrat\",\"Republican\")) %>% \n  \n  mutate(Amount = parse_number(Amount)) %>% \n  \n  group_by(League,`Election Year`,Party) %>% \n  \n  summarise(party_donations = sum(Amount)) %>% \n  \n  ungroup() \n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\")`.\nCaused by warning in `League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\")`:\n! longer object length is not a multiple of shorter object length\n\n\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `Party == c(\"Democrat\", \"Republican\")`.\nCaused by warning in `Party == c(\"Democrat\", \"Republican\")`:\n! longer object length is not a multiple of shorter object length\n\n\n`summarise()` has grouped output by 'League', 'Election Year'. You can override\nusing the `.groups` argument.\n\nskim(donation_clean)\n\n\nData summary\n\n\nName\ndonation_clean\n\n\nNumber of rows\n32\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nLeague\n0\n1\n3\n6\n0\n6\n0\n\n\nParty\n0\n1\n8\n10\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2018.0\n1.68\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇\n\n\nparty_donations\n0\n1\n138422.2\n379996.99\n1600\n9250\n18450\n65300\n1808600\n▇▁▁▁▁"
  },
  {
    "objectID": "visualization_exercise.html#plot-data",
    "href": "visualization_exercise.html#plot-data",
    "title": "Visualization Exercise",
    "section": "Plot data",
    "text": "Plot data\n\ndonation_plot <- donation_clean %>%\nggplot(aes(fill=Party, y=party_donations, x=`Election Year`)) +\n\n  geom_bar(position = \"fill\", stat = \"identity\", color = \"white\") + #basic geometry of plot, bar plot\n\n  facet_wrap(as.factor(donation_clean$League)) + #plot by individual League\n\n  scale_fill_manual(name=\"DONATIONS TO\", values=c(\"#00A5E3\", \"#CC0000\"), #looked up hexcodes on google \n  labels=c(\"DEMOCRATS\",\"REPUBLICANS\")) + #fill colors in correct order\n\n  theme_fivethirtyeight() + #theme from fivethirtyeight website\n\n  scale_x_continuous(breaks = seq(2016,2020,2)) + #2 year breaks between 2016 & 2020\n\n  labs(title = \"Across leagues, majority of donations go to Republicans\",\n  subtitle = \"Share of donations from team owners in six leagues, per year, league and party\") +\n\n  theme(legend.title = element_text(face = \"bold\", size = 16),\n  legend.text = element_text(size = 16),\n  plot.title.position = \"plot\",\n  plot.title = element_text(face = \"bold\", size = 24),\n  plot.subtitle = element_text(size = 18),\n  legend.position = \"top\",\n  axis.text.x = element_text(size = 14))\n  donation_plot\n\n\n\n\nYou will notice that the proportions on my plot are slightly different from the original. This is because I excluded all cross-listed league affiliations (for the sake of time, but in the future I would like to be able to parse these out into individual observations). I also excluded bipartisan donations and NAs because I was having trouble renaming these all to bipartisan. I would also like to work on this, as I would like to be able to re-create this chart more accurately.\nI also had some formatting issues that I couldn’t quite work out on my own. For one, I could not figure out how to change the size of the facet labels. I also struggled to find a way to change the y-axis tick labels to be percentages like on the original."
  },
  {
    "objectID": "tidytuesday_exercise.html#loading-packages-and-set-figure-size",
    "href": "tidytuesday_exercise.html#loading-packages-and-set-figure-size",
    "title": "Tidy Tuesday Exercise",
    "section": "Loading packages and set figure size",
    "text": "Loading packages and set figure size\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(skimr)\nlibrary(ggpmisc)\n\nLoading required package: ggpp\n\nAttaching package: 'ggpp'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8)"
  },
  {
    "objectID": "tidytuesday_exercise.html#data-loading",
    "href": "tidytuesday_exercise.html#data-loading",
    "title": "Tidy Tuesday Exercise",
    "section": "Data loading",
    "text": "Data loading\nFollow the TidyTuesday instructions for 2023-02-14\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "tidytuesday_exercise.html#data-exploration",
    "href": "tidytuesday_exercise.html#data-exploration",
    "title": "Tidy Tuesday Exercise",
    "section": "Data exploration",
    "text": "Data exploration\n\nskim(age_gaps)\n\n\nData summary\n\n\nName\nage_gaps\n\n\nNumber of rows\n1155\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmovie_name\n0\n1\n2\n43\n0\n830\n0\n\n\ndirector\n0\n1\n3\n31\n0\n510\n0\n\n\nactor_1_name\n0\n1\n6\n22\n0\n567\n0\n\n\nactor_2_name\n0\n1\n7\n27\n0\n647\n0\n\n\ncharacter_1_gender\n0\n1\n3\n5\n0\n2\n0\n\n\ncharacter_2_gender\n0\n1\n3\n5\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nactor_1_birthdate\n0\n1\n1889-04-16\n1996-06-01\n1964-10-03\n562\n\n\nactor_2_birthdate\n0\n1\n1906-10-06\n1996-11-11\n1974-07-30\n640\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n0\n1\n2000.80\n16.37\n1935\n1997\n2004\n2012\n2022\n▁▁▁▆▇\n\n\nage_difference\n0\n1\n10.42\n8.51\n0\n4\n8\n15\n52\n▇▃▂▁▁\n\n\ncouple_number\n0\n1\n1.40\n0.75\n1\n1\n1\n2\n7\n▇▁▁▁▁\n\n\nactor_1_age\n0\n1\n40.64\n10.42\n18\n33\n39\n47\n81\n▂▇▅▂▁\n\n\nactor_2_age\n0\n1\n30.21\n7.50\n17\n25\n29\n34\n68\n▇▇▂▁▁\n\n\n\n\n\nBy using skim(), I can see many interesting things about the data:\n\nThe mean age difference between couples is about 10 years.\nThere are 830 unique movies listed, spanning from 1935 to 2022, with most movies only having one couple each.\nSome actor names are repeated upwards of 20 times, showing that they have been involved in multiple couples."
  },
  {
    "objectID": "tidytuesday_exercise.html#ideas-for-analysis",
    "href": "tidytuesday_exercise.html#ideas-for-analysis",
    "title": "Tidy Tuesday Exercise",
    "section": "Ideas for analysis",
    "text": "Ideas for analysis\n\nI will start by designating sexuality of each couple into three groups (straight, gay, sapphic) because I am interested to see how many queer couples there are. If there are enough, we could look at age gap differences between each group.\nI will then determine which gender is the oldest in each pair because I hypothesize that men will be older more of the time.\nI will start with these two questions for now and see where they take me"
  },
  {
    "objectID": "tidytuesday_exercise.html#mutate-data",
    "href": "tidytuesday_exercise.html#mutate-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Mutate data",
    "text": "Mutate data\n\nClassifying sexuality of each couple\nHere I will create a new variable called sexuality based on whether each couple is of same or opposite gender, creating three labels for these relationships: straight (man & woman), gay (man & man), and sapphic (woman & woman)\nI will also look at how many observations there are for each sexuality.\n\nage_gaps_sexuality <- age_gaps %>% \n  mutate(sexuality = case_when(character_1_gender == 'man' & character_2_gender == 'woman' ~ 'straight',\n                               character_1_gender == 'man' & character_2_gender == 'man' ~ 'gay',\n                               character_1_gender == 'woman' & character_2_gender == 'woman' ~ 'sapphic',\n                               character_2_gender == 'man' & character_1_gender == 'woman' ~ 'straight',\n                               character_2_gender == 'man' & character_1_gender == 'man' ~ 'gay',\n                               character_2_gender == 'woman' & character_1_gender == 'woman' ~ 'sapphic'))\nsexuality_count <- age_gaps_sexuality %>% count(sexuality)\nsexuality_count <- sexuality_count %>% mutate(proportion = n/sum(n))\ntibble(sexuality_count)\n\n# A tibble: 3 × 3\n  sexuality     n proportion\n  <chr>     <int>      <dbl>\n1 gay          12    0.0104 \n2 sapphic      11    0.00952\n3 straight   1132    0.980  \n\n\nHere, you see that 98% of couples in this data set can be defined as heterosexual.\n\n\nCounting how many times each gender is older than their partner\nHere, I will count the number of times each gender is older and then calculate that proportion.\n\nolder_count <- age_gaps %>% count(character_1_gender)\nolder_count <- older_count %>% mutate(proportion = n/sum(n))\ntibble(older_count)\n\n# A tibble: 2 × 3\n  character_1_gender     n proportion\n  <chr>              <int>      <dbl>\n1 man                  941      0.815\n2 woman                214      0.185\n\n\nAs you can see here, men in Hollywood are much more likely to be older than their partner than women are. In this data set, men were older than their partner 80% of the time."
  },
  {
    "objectID": "tidytuesday_exercise.html#data-visualization",
    "href": "tidytuesday_exercise.html#data-visualization",
    "title": "Tidy Tuesday Exercise",
    "section": "Data visualization",
    "text": "Data visualization\n\nDifference in average age gaps between straight, gay, and sapphic couples\n\nage_gaps_sexuality %>% ggplot(aes(sexuality, age_difference, color = sexuality)) +\n  geom_boxplot() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nIt appears that gay couples have a higher average age gap than other sexualities, but remember that they make up less than 1% of observations\n\n\nProportion of sexualities in couples throughout the years\n\nage_gaps_sexuality %>% ggplot(aes(y = couple_number, x = release_year, fill = sexuality)) + \n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(name = \"Year Released\", breaks = seq(1930,2022,10)) +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nOnly straight couples were documented in Hollywood prior to the 1990s. Queer couplings began to be documented in the 1990s and early 2000s, but still make up a small portion of couples which we saw earlier. We can also note that queer couplings started to pop up around the time that couple numbers in Hollywood dramatically increased in the late 1990s.\n\n\nDifference in age gaps between older men and women\n\nage_gaps %>% ggplot(aes(character_1_gender, age_difference, color = character_1_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, older men tend to have a higher age gap with their partner than older women do.\n\n\nDifference in age gaps between younger men and women\n\nage_gaps %>% ggplot(aes(character_2_gender, age_difference, color = character_2_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, younger men tend to have a smaller age gap with their partners compared to younger women who have a larger average age gap.\n\n\nLinear regression of age vs age gap between men and women\n\nage_gaps %>% ggplot(aes(actor_1_age, age_difference, color = character_1_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(name = \"Gender\", values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of older partner's age vs. relationship age gap\")\n\n\n\n\nMen in Hollywood who are older are more likely to have an increased age gap in their relationships as they age.\n\nage_gaps %>% ggplot(aes(actor_2_age, age_difference, color = character_2_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of younger parter's age vs. relationship age gap\")\n\n\n\n\nWe do not see this same trend with the younger partners. There are less men who are younger than their partner, and there seems to be no indication that their age is a determining factor in their relationship age gap.\nThere are far more women who are younger than their partner, and overall it appears there are less women in couples past the age of 40, compared to the first scatter plot where men are in couples well past their 40s."
  },
  {
    "objectID": "tidytuesday_exercise.html#discussion-and-conclusions",
    "href": "tidytuesday_exercise.html#discussion-and-conclusions",
    "title": "Tidy Tuesday Exercise",
    "section": "Discussion and conclusions",
    "text": "Discussion and conclusions\nWhat I learned from looking at this data of Hollywood couples on the same movie set:\n\n98% of documented couples were heterosexual\nMen were more likely to date someone younger than them then women were\nOlder men had a higher average age gap in their relationships, meaning they were more likely to date women much younger than them than older women were to date much younger men\nOlder partners of both genders showed an increase in relationship age gaps as their own age increased, although this was much more pronounced for men, meaning that as these men age, they continue to date young women\n\nFrom this data exploration, I have concluded that on average, men in Hollywood tend to date much younger women than themselves. They also continue to date much younger women as they age. I would also be interested in looking at the average age of all men recorded vs the average age of women because I have a feeling that men on average are older.\nTo conclude, and to quote Taylor Swift, “I’ll get older, but your lovers stay my age”."
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "Flu Data Model Fitting",
    "section": "",
    "text": "library(tidymodels)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(dotwhisker)\n\n\n\n\n\nsymptoms_fit <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))\ntibble(symptoms_fit) #quick look at data\n\n# A tibble: 730 × 32\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ CoughYN Sneeze Fatigue Subje…⁵ Heada…⁶\n   <fct>          <fct>   <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      Yes     No     Yes     Yes     Yes    \n 2 Yes            Yes     No      Yes     Yes     No     Yes     Yes     Yes    \n 3 Yes            Yes     Yes     Yes     No      Yes    Yes     Yes     Yes    \n 4 Yes            Yes     Yes     Yes     Yes     Yes    Yes     Yes     Yes    \n 5 Yes            No      Yes     No      No      No     Yes     Yes     Yes    \n 6 No             No      Yes     No      Yes     Yes    Yes     Yes     Yes    \n 7 No             No      Yes     No      Yes     No     Yes     Yes     No     \n 8 No             Yes     Yes     Yes     Yes     Yes    Yes     Yes     Yes    \n 9 Yes            Yes     Yes     Yes     Yes     No     Yes     Yes     Yes    \n10 No             Yes     No      Yes     Yes     No     Yes     No      Yes    \n# … with 720 more rows, 23 more variables: Weakness <fct>, WeaknessYN <fct>,\n#   CoughIntensity <fct>, CoughYN2 <fct>, Myalgia <fct>, MyalgiaYN <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Hearing <fct>, Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>,\n#   Vision <fct>, Vomit <fct>, Wheeze <fct>, BodyTemp <dbl>, and abbreviated\n#   variable names ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, …\n\n\nData looks good to go\n\n\n\n\n\n\ndata_split <- initial_split(symptoms_fit, prop = 3/4)\n\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n\n\n\n\n\nlm_mod <- linear_reg() #set model type as linear regression\n\n\n\n\n\nrecipe_bodytemp <- recipe(BodyTemp ~ ., data = train_data)\n\n\n\n\n\nbodytemp_lm_workflow <- workflow() %>% \n  add_model(lm_mod) %>% \n  add_recipe(recipe_bodytemp)\n\n\n\n\n\nbodytemp_fit <- bodytemp_lm_workflow %>% \n  fit(data = train_data)\ntidy(bodytemp_fit)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic  p.value\n   <chr>                   <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)           98.2        0.346  284.     0       \n 2 SwollenLymphNodesYes  -0.108      0.106   -1.01   0.313   \n 3 ChestCongestionYes     0.0478     0.115    0.414  0.679   \n 4 ChillsSweatsYes        0.313      0.145    2.15   0.0320  \n 5 NasalCongestionYes    -0.213      0.131   -1.63   0.105   \n 6 CoughYNYes             0.405      0.289    1.40   0.163   \n 7 SneezeYes             -0.374      0.112   -3.34   0.000912\n 8 FatigueYes             0.111      0.186    0.596  0.552   \n 9 SubjectiveFeverYes     0.348      0.121    2.88   0.00412 \n10 HeadacheYes            0.0126     0.149    0.0847 0.933   \n# … with 28 more rows\n\n\n\n\n\n\ntidy(bodytemp_fit) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, \n                            colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\n\n\nbodytemp_aug_test <- augment(bodytemp_fit, test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\nbodytemp_aug_test %>% select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.1\n 2    100.   99.5\n 3    102.   99.5\n 4     98.4  98.8\n 5     98.2  99.2\n 6     99.2  98.8\n 7     98.5  99.0\n 8     98.2  98.6\n 9    100.   99.0\n10    100    99.0\n# … with 173 more rows\n\n\n\n\n\nInfo on RMSE or Root Mean Squared Error can be found here.\n\nbodytemp_aug_test %>% \n  rmse(truth = BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.20\n\n\nI think this means that this model is estimating body temp incorrectly by this amount (in either direction)\n\n\n\n\nPredictor of interest: Runny nose\n\n\nSince we already defined the training set and testing set, we don’t need to do that again. We will just reuse those. We also already defined the model, so we don’t need to do that again.\n\nrecipe_bodytemp2 <- recipe(BodyTemp ~ RunnyNose, data = train_data)\n\nHere, we have set the outcome of interest to be body temperature, and predictor of interest to be runny nose.\n\n\n\n\nbodytemp_lm_workflow2 <- workflow() %>% \n  add_model(lm_mod) %>% \n  add_recipe(recipe_bodytemp2)\n\n\n\n\n\nbodytemp_fit2 <- bodytemp_lm_workflow2 %>% \n  fit(data = train_data)\ntidy(bodytemp_fit2)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0931   1065.   0      \n2 RunnyNoseYes   -0.317    0.110      -2.88 0.00419\n\n\nNow we have trained the model using the training data set.\n\n\n\n\ntidy(bodytemp_fit2) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, \n                            colour = \"grey50\", linetype = 2))\n\n\n\n\nLooks like runny nose is a negative predictor of body temp (body temp is more likely to be lower if runny nose symptom is present)\n\n\n\n\nbodytemp_aug_test2 <- augment(bodytemp_fit2, test_data)\nbodytemp_aug_test2 %>% select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.1\n 2    100.   99.1\n 3    102.   98.8\n 4     98.4  98.8\n 5     98.2  99.1\n 6     99.2  98.8\n 7     98.5  98.8\n 8     98.2  98.8\n 9    100.   98.8\n10    100    98.8\n# … with 173 more rows\n\n\n\n\n\n\nbodytemp_aug_test2 %>% \n  rmse(truth = BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.26\n\n\nThis is a similar output to what we saw in the first model, where estimation of body temp is slightly off by about 1 degree.\n\n\n\n\n\n\nWe will continue to use the model testing and training data sets that we created at the start. However, since we now want to create a logistic regression (outcome of interest is categorical), we will need to define a new model\n\nlog_mod <- logistic_reg() %>% \n  set_engine(\"glm\")\n\n\n\n\n\nrecipe_nausea <- recipe(Nausea ~., data = train_data)\n\nThis sets the stage to predict nausea outcomes based on all other variables in the data set (predictors)\n\n\n\n\nnausea_log_wf <- workflow() %>% \n  add_model(log_mod) %>% \n  add_recipe(recipe_nausea)\n\n\n\n\n\nnausea_fit <- nausea_log_wf %>% \n  fit(data = train_data)\n\nnausea_fit %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           -9.21       9.18    -1.00     0.316\n 2 SwollenLymphNodesYes  -0.274      0.231   -1.19     0.235\n 3 ChestCongestionYes     0.337      0.256    1.32     0.188\n 4 ChillsSweatsYes        0.254      0.335    0.757    0.449\n 5 NasalCongestionYes     0.415      0.296    1.40     0.161\n 6 CoughYNYes            -0.382      0.603   -0.633    0.527\n 7 SneezeYes              0.231      0.245    0.943    0.346\n 8 FatigueYes             0.0278     0.429    0.0649   0.948\n 9 SubjectiveFeverYes     0.419      0.267    1.57     0.117\n10 HeadacheYes            0.364      0.346    1.05     0.292\n# … with 28 more rows\n\n\nNow we have trained the model, so let’s use the test data to see how well this model predicts nausea.\n\n\n\n\npredict(nausea_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 Yes        \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 Yes        \n# … with 173 more rows\n\n\n\n\n\nInfo on ROC curves or Receiver Operating Characteristic can be found here.\n\nnausea_aug_test <- augment(nausea_fit, test_data)\n\nnausea_aug_test %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.773\n\n\nI think what this shows is that the model is a pretty decent predictor of nausea, however, it is more sensitive than it is specific, meaning that it is good at indicating true positives but not as good at indicating true negatives.\n\n\n\n\nPredictor of interest: Runny nose\n\n\nSince we have already split the data and defined the appropriate model, we will just need to create a new recipe that predicts nausea based on runny nose.\n\nrecipe_nausea2 <- recipe(Nausea ~ RunnyNose, data = train_data)\n\n\n\n\n\nnausea_log_wf2 <- workflow() %>% \n  add_model(log_mod) %>% \n  add_recipe(recipe_nausea2)\n\n\n\n\n\nnausea_fit2 <- nausea_log_wf2 %>% \n  fit(data = train_data)\n\nnausea_fit2 %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -0.590      0.167    -3.54  0.000400\n2 RunnyNoseYes  -0.0804     0.198    -0.406 0.685   \n\n\n\n\n\n\npredict(nausea_fit2, test_data)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 173 more rows\n\n\n\n\n\n\nnausea_aug_test2 <- augment(nausea_fit2, test_data)\n\nnausea_aug_test2 %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.456"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Flu Data Exploration",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\n\n\n\n\n\nsymptoms_clean <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))\n\n\n\n\n\nskimr::skim(symptoms_clean)\n\n\nData summary\n\n\nName\nsymptoms_clean\n\n\nNumber of rows\n730\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n31\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSwollenLymphNodes\n0\n1\nFALSE\n2\nNo: 418, Yes: 312\n\n\nChestCongestion\n0\n1\nFALSE\n2\nYes: 407, No: 323\n\n\nChillsSweats\n0\n1\nFALSE\n2\nYes: 600, No: 130\n\n\nNasalCongestion\n0\n1\nFALSE\n2\nYes: 563, No: 167\n\n\nCoughYN\n0\n1\nFALSE\n2\nYes: 655, No: 75\n\n\nSneeze\n0\n1\nFALSE\n2\nYes: 391, No: 339\n\n\nFatigue\n0\n1\nFALSE\n2\nYes: 666, No: 64\n\n\nSubjectiveFever\n0\n1\nFALSE\n2\nYes: 500, No: 230\n\n\nHeadache\n0\n1\nFALSE\n2\nYes: 615, No: 115\n\n\nWeakness\n0\n1\nFALSE\n4\nMod: 338, Mil: 223, Sev: 120, Non: 49\n\n\nWeaknessYN\n0\n1\nFALSE\n2\nYes: 681, No: 49\n\n\nCoughIntensity\n0\n1\nFALSE\n4\nMod: 357, Sev: 172, Mil: 154, Non: 47\n\n\nCoughYN2\n0\n1\nFALSE\n2\nYes: 683, No: 47\n\n\nMyalgia\n0\n1\nFALSE\n4\nMod: 325, Mil: 213, Sev: 113, Non: 79\n\n\nMyalgiaYN\n0\n1\nFALSE\n2\nYes: 651, No: 79\n\n\nRunnyNose\n0\n1\nFALSE\n2\nYes: 519, No: 211\n\n\nAbPain\n0\n1\nFALSE\n2\nNo: 639, Yes: 91\n\n\nChestPain\n0\n1\nFALSE\n2\nNo: 497, Yes: 233\n\n\nDiarrhea\n0\n1\nFALSE\n2\nNo: 631, Yes: 99\n\n\nEyePn\n0\n1\nFALSE\n2\nNo: 617, Yes: 113\n\n\nInsomnia\n0\n1\nFALSE\n2\nYes: 415, No: 315\n\n\nItchyEye\n0\n1\nFALSE\n2\nNo: 551, Yes: 179\n\n\nNausea\n0\n1\nFALSE\n2\nNo: 475, Yes: 255\n\n\nEarPn\n0\n1\nFALSE\n2\nNo: 568, Yes: 162\n\n\nHearing\n0\n1\nFALSE\n2\nNo: 700, Yes: 30\n\n\nPharyngitis\n0\n1\nFALSE\n2\nYes: 611, No: 119\n\n\nBreathless\n0\n1\nFALSE\n2\nNo: 436, Yes: 294\n\n\nToothPn\n0\n1\nFALSE\n2\nNo: 565, Yes: 165\n\n\nVision\n0\n1\nFALSE\n2\nNo: 711, Yes: 19\n\n\nVomit\n0\n1\nFALSE\n2\nNo: 652, Yes: 78\n\n\nWheeze\n0\n1\nFALSE\n2\nNo: 510, Yes: 220\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBodyTemp\n0\n1\n98.94\n1.2\n97.2\n98.2\n98.5\n99.3\n103.1\n▇▇▂▁▁\n\n\n\n\n\nLooks like the data did load properly. There are 730 observations of 32 variables with no NAs. There are 31 factor and 1 integer variables.\n\n\n\nOutcomes of interest: body temperature, nausea\nPredictors of interest: weakness, fatigue, headache\n\n\n\n\nsummary(symptoms_clean)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion CoughYN  \n No :418           No :323         No :130      No :167         No : 75  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:655  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Sneeze    Fatigue   SubjectiveFever Headache      Weakness   WeaknessYN\n No :339   No : 64   No :230         No :115   None    : 49   No : 49   \n Yes:391   Yes:666   Yes:500         Yes:615   Mild    :223   Yes:681   \n                                               Moderate:338             \n                                               Severe  :120             \n                                                                        \n                                                                        \n  CoughIntensity CoughYN2      Myalgia    MyalgiaYN RunnyNose AbPain   \n None    : 47    No : 47   None    : 79   No : 79   No :211   No :639  \n Mild    :154    Yes:683   Mild    :213   Yes:651   Yes:519   Yes: 91  \n Moderate:357              Moderate:325                                \n Severe  :172              Severe  :113                                \n                                                                       \n                                                                       \n ChestPain Diarrhea  EyePn     Insomnia  ItchyEye  Nausea    EarPn    \n No :497   No :631   No :617   No :315   No :551   No :475   No :568  \n Yes:233   Yes: 99   Yes:113   Yes:415   Yes:179   Yes:255   Yes:162  \n                                                                      \n                                                                      \n                                                                      \n                                                                      \n Hearing   Pharyngitis Breathless ToothPn   Vision    Vomit     Wheeze   \n No :700   No :119     No :436    No :565   No :711   No :652   No :510  \n Yes: 30   Yes:611     Yes:294    Yes:165   Yes: 19   Yes: 78   Yes:220  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n    BodyTemp     \n Min.   : 97.20  \n 1st Qu.: 98.20  \n Median : 98.50  \n Mean   : 98.94  \n 3rd Qu.: 99.30  \n Max.   :103.10  \n\n\nHere we see that most of the categorical variables have either Yes or No responses, simply indicating presence-absence of the symptoms. A few others have a range of responses to address the severity of certain symptoms. There is one continuous variable, BodyTemp, which has a range from 97.2 to 103.1. Nausea, our other outcome of interest, had 475 No and 255 Yes.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(BodyTemp)) +\n  geom_histogram(fill = \"#d65aa8\") +\n  theme_light()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nHere we see the distribution of BodyTemp, showing that the most commonly reported body temperature was slightly higher than 98. This checks out, as we saw in the summary report above than the median is 98.5.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(WeaknessYN, BodyTemp, color = WeaknessYN)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nFrom first glance, it appears as if mean body temp increases when weakness is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Fatigue, BodyTemp, color = Fatigue)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nIt appears that mean body temp does increase slightly when fatigue is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Headache, BodyTemp, color = Headache)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nIt appears that mean body temp does increase slightly when headache is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(WeaknessYN, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nThe most common combination is weakness + no nausea, followed by weakness + nausea. The count size is similar for both though, so there may or may not a significant difference there. The least common observation is lack of weakness but presence of nausea. What this shows is that weakness is more common than no weakness, but that weakness may not necessarily determine nausea.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Fatigue, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nThis output is similar to the one above, where presence of fatigue is most common, but fatigue without the presence of nausea is slightly more common.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Headache, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nLike in the previous two outputs, headaches are more common than not, but lack of nausea with headaches was slightly more common than presence of nausea."
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Flu Data Wrangling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\n\n\n\n\n\nsymptoms <- readRDS(here(\"fluanalysis/data/raw_data/SympAct_Any_Pos.Rda\"))\n\n\n\n\n\nglimpse(symptoms)\n\nRows: 735\nColumns: 63\n$ DxName1           <fct> \"Influenza like illness - Clinical Dx\", \"Acute tonsi…\n$ DxName2           <fct> NA, \"Influenza like illness - Clinical Dx\", \"Acute p…\n$ DxName3           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Fever, unspecified\"…\n$ DxName4           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Other fatigue\", NA,…\n$ DxName5           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Headache\", NA, NA, …\n$ Unique.Visit      <chr> \"340_17632125\", \"340_17794836\", \"342_17737773\", \"342…\n$ ActivityLevel     <int> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ ActivityLevelF    <fct> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n$ RapidFluA         <fct> Presumptive Negative For Influenza A, NA, Presumptiv…\n$ RapidFluB         <fct> Presumptive Negative For Influenza B, NA, Presumptiv…\n$ PCRFluA           <fct> NA, NA, NA, NA, NA, NA,  Influenza A Not Detected, N…\n$ PCRFluB           <fct> NA, NA, NA, NA, NA, NA,  Influenza B Not Detected, N…\n$ TransScore1       <dbl> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore1F      <fct> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore2       <dbl> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore2F      <fct> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore3       <dbl> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore3F      <fct> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore4       <dbl> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ TransScore4F      <fct> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ ImpactScore       <int> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2      <int> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3      <int> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreF      <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2F     <fct> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3F     <fct> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreFD     <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ TotalSymp1        <dbl> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp1F       <fct> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp2        <dbl> 8, 10, 17, 16, 11, 14, 10, 11, 13, 10, 14, 19, 13, 1…\n$ TotalSymp3        <dbl> 8, 9, 16, 15, 11, 14, 10, 10, 12, 9, 13, 18, 12, 16,…\n\nskimr::skim(symptoms)\n\n\nData summary\n\n\nName\nsymptoms\n\n\nNumber of rows\n735\n\n\nNumber of columns\n63\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n50\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nUnique.Visit\n0\n1\n10\n12\n0\n735\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nDxName1\n0\n1.00\nFALSE\n25\nInf: 328, Inf: 131, Fev: 101, Cou: 66\n\n\nDxName2\n280\n0.62\nFALSE\n42\nInf: 126, Inf: 115, Fev: 45, Cou: 41\n\n\nDxName3\n626\n0.15\nFALSE\n37\nInf: 23, Inf: 14, Cou: 10, Fev: 6\n\n\nDxName4\n716\n0.03\nFALSE\n14\nInf: 3, Acu: 2, Enc: 2, Inf: 2\n\n\nDxName5\n734\n0.00\nFALSE\n1\nHea: 1, Acu: 0, Enc: 0, Oth: 0\n\n\nActivityLevelF\n0\n1.00\nFALSE\n11\n3: 125, 5: 97, 4: 95, 2: 80\n\n\nSwollenLymphNodes\n0\n1.00\nFALSE\n2\nNo: 421, Yes: 314\n\n\nChestCongestion\n0\n1.00\nFALSE\n2\nYes: 409, No: 326\n\n\nChillsSweats\n0\n1.00\nFALSE\n2\nYes: 604, No: 131\n\n\nNasalCongestion\n0\n1.00\nFALSE\n2\nYes: 565, No: 170\n\n\nCoughYN\n0\n1.00\nFALSE\n2\nYes: 660, No: 75\n\n\nSneeze\n0\n1.00\nFALSE\n2\nYes: 395, No: 340\n\n\nFatigue\n0\n1.00\nFALSE\n2\nYes: 671, No: 64\n\n\nSubjectiveFever\n0\n1.00\nFALSE\n2\nYes: 505, No: 230\n\n\nHeadache\n0\n1.00\nFALSE\n2\nYes: 620, No: 115\n\n\nWeakness\n0\n1.00\nFALSE\n4\nMod: 341, Mil: 224, Sev: 121, Non: 49\n\n\nWeaknessYN\n0\n1.00\nFALSE\n2\nYes: 686, No: 49\n\n\nCoughIntensity\n0\n1.00\nFALSE\n4\nMod: 360, Sev: 172, Mil: 156, Non: 47\n\n\nCoughYN2\n0\n1.00\nFALSE\n2\nYes: 688, No: 47\n\n\nMyalgia\n0\n1.00\nFALSE\n4\nMod: 327, Mil: 214, Sev: 115, Non: 79\n\n\nMyalgiaYN\n0\n1.00\nFALSE\n2\nYes: 656, No: 79\n\n\nRunnyNose\n0\n1.00\nFALSE\n2\nYes: 524, No: 211\n\n\nAbPain\n0\n1.00\nFALSE\n2\nNo: 642, Yes: 93\n\n\nChestPain\n0\n1.00\nFALSE\n2\nNo: 501, Yes: 234\n\n\nDiarrhea\n0\n1.00\nFALSE\n2\nNo: 636, Yes: 99\n\n\nEyePn\n0\n1.00\nFALSE\n2\nNo: 622, Yes: 113\n\n\nInsomnia\n0\n1.00\nFALSE\n2\nYes: 419, No: 316\n\n\nItchyEye\n0\n1.00\nFALSE\n2\nNo: 553, Yes: 182\n\n\nNausea\n0\n1.00\nFALSE\n2\nNo: 477, Yes: 258\n\n\nEarPn\n0\n1.00\nFALSE\n2\nNo: 573, Yes: 162\n\n\nHearing\n0\n1.00\nFALSE\n2\nNo: 705, Yes: 30\n\n\nPharyngitis\n0\n1.00\nFALSE\n2\nYes: 614, No: 121\n\n\nBreathless\n0\n1.00\nFALSE\n2\nNo: 438, Yes: 297\n\n\nToothPn\n0\n1.00\nFALSE\n2\nNo: 569, Yes: 166\n\n\nVision\n0\n1.00\nFALSE\n2\nNo: 716, Yes: 19\n\n\nVomit\n0\n1.00\nFALSE\n2\nNo: 656, Yes: 79\n\n\nWheeze\n0\n1.00\nFALSE\n2\nNo: 514, Yes: 221\n\n\nRapidFluA\n407\n0.45\nFALSE\n2\nPos: 169, Pre: 159\n\n\nRapidFluB\n407\n0.45\nFALSE\n2\nPre: 302, Pos: 26\n\n\nPCRFluA\n581\n0.21\nFALSE\n3\nIn: 120, In: 33, Ind: 1, Ass: 0\n\n\nPCRFluB\n581\n0.21\nFALSE\n2\nIn: 145, In: 9, Ass: 0\n\n\nTransScore1F\n0\n1.00\nFALSE\n6\n4: 210, 5: 195, 3: 157, 2: 107\n\n\nTransScore2F\n0\n1.00\nFALSE\n5\n4: 294, 3: 201, 2: 138, 1: 89\n\n\nTransScore3F\n0\n1.00\nFALSE\n4\n3: 323, 2: 222, 1: 166, 0: 24\n\n\nTransScore4F\n0\n1.00\nFALSE\n5\n3: 230, 4: 198, 2: 154, 1: 103\n\n\nImpactScoreF\n0\n1.00\nFALSE\n17\n8: 105, 9: 104, 10: 88, 7: 84\n\n\nImpactScore2F\n0\n1.00\nFALSE\n16\n7: 107, 8: 102, 9: 90, 10: 86\n\n\nImpactScore3F\n0\n1.00\nFALSE\n14\n4: 134, 5: 112, 3: 108, 6: 102\n\n\nImpactScoreFD\n0\n1.00\nFALSE\n17\n8: 105, 9: 104, 10: 88, 7: 84\n\n\nTotalSymp1F\n0\n1.00\nFALSE\n19\n12: 86, 13: 84, 14: 80, 11: 72\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nActivityLevel\n0\n1.00\n4.46\n2.64\n0.0\n3.0\n4.0\n6.0\n10.0\n▆▇▆▅▂\n\n\nBodyTemp\n5\n0.99\n98.94\n1.20\n97.2\n98.2\n98.5\n99.3\n103.1\n▇▇▂▁▁\n\n\nTransScore1\n0\n1.00\n3.47\n1.31\n0.0\n3.0\n4.0\n5.0\n5.0\n▂▅▆▇▇\n\n\nTransScore2\n0\n1.00\n2.92\n1.11\n0.0\n2.0\n3.0\n4.0\n4.0\n▁▂▃▆▇\n\n\nTransScore3\n0\n1.00\n2.15\n0.88\n0.0\n1.0\n2.0\n3.0\n3.0\n▁▅▁▆▇\n\n\nTransScore4\n0\n1.00\n2.58\n1.21\n0.0\n2.0\n3.0\n4.0\n4.0\n▂▃▆▇▇\n\n\nImpactScore\n0\n1.00\n9.51\n2.84\n2.0\n8.0\n9.0\n11.0\n18.0\n▂▇▇▅▁\n\n\nImpactScore2\n0\n1.00\n8.58\n2.78\n2.0\n7.0\n8.0\n10.0\n17.0\n▂▇▆▃▁\n\n\nImpactScore3\n0\n1.00\n5.06\n2.34\n0.0\n3.0\n5.0\n7.0\n13.0\n▂▇▃▂▁\n\n\nTotalSymp1\n0\n1.00\n12.99\n3.41\n5.0\n11.0\n13.0\n15.0\n23.0\n▂▇▇▅▁\n\n\nTotalSymp2\n0\n1.00\n12.43\n3.22\n4.0\n10.0\n12.0\n15.0\n22.0\n▁▇▇▅▁\n\n\nTotalSymp3\n0\n1.00\n11.66\n3.10\n3.0\n10.0\n12.0\n14.0\n21.0\n▁▇▇▅▁\n\n\n\n\n\nAfter viewing the data, I see there are 63 variables and 735 observations. Most are coded as factors and integers, and there is 1 character variable. Some variables have quite a good amount of NAs.\n\n\n\n\nsymptoms <- symptoms %>% select(9:40) %>% select(!contains(\"YN\", ignore.case = FALSE))\n\nSince all the variables of interest were all consecutive, I was able to easily select them based on their range of column number.\nI then selected for all variables that did not include “YN”, removing duplicate variables.\n\n\n\nsummary(symptoms) #Vison and Hearing have the less than 50 yes\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   \n No :421           No :326         No :131      No :170         No :340  \n Yes:314           Yes:409         Yes:604      Yes:565         Yes:395  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity\n No : 64   No :230         No :115   None    : 49   None    : 47   \n Yes:671   Yes:505         Yes:620   Mild    :224   Mild    :156   \n                                     Moderate:341   Moderate:360   \n                                     Severe  :121   Severe  :172   \n                                                                   \n                                                                   \n                                                                   \n     Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia \n None    : 79   No :211   No :642   No :501   No :636   No :622   No :316  \n Mild    :214   Yes:524   Yes: 93   Yes:234   Yes: 99   Yes:113   Yes:419  \n Moderate:327                                                              \n Severe  :115                                                              \n                                                                           \n                                                                           \n                                                                           \n ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  \n No :553   No :477   No :573   No :705   No :121     No :438    No :569  \n Yes:182   Yes:258   Yes:162   Yes: 30   Yes:614     Yes:297    Yes:166  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Vision    Vomit     Wheeze       BodyTemp     \n No :716   No :656   No :514   Min.   : 97.20  \n Yes: 19   Yes: 79   Yes:221   1st Qu.: 98.20  \n                               Median : 98.50  \n                               Mean   : 98.94  \n                               3rd Qu.: 99.30  \n                               Max.   :103.10  \n                               NA's   :5       \n\nsymptoms <- symptoms %>% select(!c(Vision, Hearing))\n\n\n\n\n\n\nsymptoms <- symptoms %>% na.omit()\n\nOnly 5 observations were removed, so it looks like we took care of most of the NAs when we selected for the relevant variables.\n\n\n\n\nsaveRDS(symptoms, here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))"
  },
  {
    "objectID": "visualization_exercise.html#load-packages",
    "href": "visualization_exercise.html#load-packages",
    "title": "Visualization Exercise",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse) #for data cleaning\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here) #for setting file paths\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\nlibrary(ggthemes) #for loading ggplot themes\nlibrary(skimr) #for skimming data sets"
  },
  {
    "objectID": "visualization_exercise.html#set-figure-size",
    "href": "visualization_exercise.html#set-figure-size",
    "title": "Visualization Exercise",
    "section": "Set figure size",
    "text": "Set figure size\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8)"
  },
  {
    "objectID": "coding_exercise.html#load-the-packages",
    "href": "coding_exercise.html#load-the-packages",
    "title": "R Coding Exercise",
    "section": "Load the packages",
    "text": "Load the packages\n\nlibrary(dslabs)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(broom)"
  },
  {
    "objectID": "coding_exercise.html#subsetting-data",
    "href": "coding_exercise.html#subsetting-data",
    "title": "R Coding Exercise",
    "section": "Subsetting data",
    "text": "Subsetting data\nI want to continue to explore the data related to African countries, specifically how gdp and infant mortality relates to fertility.\n\n#subset African countries\nafricadata <- filter(gapminder, continent == \"Africa\")\n\n#select only the `gdp` and `fertility` columns and assign to `gdpfert`\ngdpfert <- africadata %>% select(gdp, fertility)\n\n#select only the `fertility` and `infant_mortality` columns and assign to `fertmort`\nfertmort <- africadata %>% select(fertility, infant_mortality)"
  },
  {
    "objectID": "coding_exercise.html#plotting-the-data",
    "href": "coding_exercise.html#plotting-the-data",
    "title": "R Coding Exercise",
    "section": "Plotting the data",
    "text": "Plotting the data\nNext, I wanted to look at the plots for the two new datasets. For both gdpfert and fertmort, I plotted the data points using geom_point() and geom_smooth() to produce a scatter plot with a smoothed line over the data. The smoothed line helps visualize patterns in the plot.\n\n#produce scatter plot with smooth line; x = gdp, y = fertility\n#x-axis log transformed for gdp data\nggplot(gdpfert, aes(gdp, fertility))+\n  geom_point() + \n  geom_smooth()+\n  scale_x_continuous(trans = \"log\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 637 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 637 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see a distinct negative correlation with fertility after the GDP of a country reaches above approx. 9.7 billion dollars. Note that most African countries have a GDP between 485 million and $9.7 billion dollars where the line fluctuates around 6 children per woman.\n\n#produce scatter plot with smooth line; x = fertility, y = infant_mortality\nggplot(fertmort, aes(fertility, infant_mortality)) +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 226 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\nHere, fertility and infant mortality are positively correlated until approximately 7 children per woman or 125 infants deaths per 1000."
  },
  {
    "objectID": "coding_exercise.html#linear-modeling",
    "href": "coding_exercise.html#linear-modeling",
    "title": "R Coding Exercise",
    "section": "Linear modeling",
    "text": "Linear modeling\nI would like to consider a linear model predicting fertility from GDP and infant mortality for African countries. The glm() function will be used to create a linear model for this scenario. The tidy() function from the broom package produces the summary of the model.\n\nfit3 <- glm(fertility ~ gdp + infant_mortality, data = africadata)\n\ntidy(fit3)\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)       3.91e+ 0  5.49e- 2      71.2 0        \n2 gdp              -1.41e-11  9.62e-13     -14.7 1.45e- 46\n3 infant_mortality  2.18e- 2  4.99e- 4      43.6 4.58e-300\n\n\nBoth GDP and infant mortality has a statistically significant affect on fertility (p-values > 0.001). GDP has an extremely small negative effect on fertility (slope = -1.411e-11), and infant mortality has a small positive effect (slope = 2.176e-2)."
  },
  {
    "objectID": "index.html#please-use-the-menu-bar-above-to-look-at-exercises-i-have-completed-for-this-course",
    "href": "index.html#please-use-the-menu-bar-above-to-look-at-exercises-i-have-completed-for-this-course",
    "title": "Leah Lariscy’s Data Analysis Portfolio",
    "section": "Please use the Menu Bar above to look at exercises I have completed for this course!",
    "text": "Please use the Menu Bar above to look at exercises I have completed for this course!"
  },
  {
    "objectID": "index.html#please-use-the-menu-bar-above-to-look-at-exercises-i-have-completed",
    "href": "index.html#please-use-the-menu-bar-above-to-look-at-exercises-i-have-completed",
    "title": "Leah Lariscy’s Data Analysis Portfolio",
    "section": "Please use the Menu Bar above to look at exercises I have completed!",
    "text": "Please use the Menu Bar above to look at exercises I have completed!"
  },
  {
    "objectID": "index.html#please-use-the-menu-bar-above-to-read-about-me-and-look-at-exercises-i-have-completed",
    "href": "index.html#please-use-the-menu-bar-above-to-read-about-me-and-look-at-exercises-i-have-completed",
    "title": "Leah Lariscy’s Data Analysis Portfolio",
    "section": "Please use the menu bar above to read about me and look at exercises I have completed!",
    "text": "Please use the menu bar above to read about me and look at exercises I have completed!"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Model Evaluation",
    "section": "",
    "text": "library(tidymodels)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(dotwhisker)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#load-data",
    "href": "fluanalysis/code/modeleval.html#load-data",
    "title": "Model Evaluation",
    "section": "Load Data",
    "text": "Load Data\n\nsymptoms_fit <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))\ncolnames(symptoms_fit) #quick look at data\n\n [1] \"SwollenLymphNodes\" \"ChestCongestion\"   \"ChillsSweats\"     \n [4] \"NasalCongestion\"   \"CoughYN\"           \"Sneeze\"           \n [7] \"Fatigue\"           \"SubjectiveFever\"   \"Headache\"         \n[10] \"Weakness\"          \"WeaknessYN\"        \"CoughIntensity\"   \n[13] \"CoughYN2\"          \"Myalgia\"           \"MyalgiaYN\"        \n[16] \"RunnyNose\"         \"AbPain\"            \"ChestPain\"        \n[19] \"Diarrhea\"          \"EyePn\"             \"Insomnia\"         \n[22] \"ItchyEye\"          \"Nausea\"            \"EarPn\"            \n[25] \"Hearing\"           \"Pharyngitis\"       \"Breathless\"       \n[28] \"ToothPn\"           \"Vision\"            \"Vomit\"            \n[31] \"Wheeze\"            \"BodyTemp\""
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#data-split",
    "href": "fluanalysis/code/modeleval.html#data-split",
    "title": "Model Evaluation",
    "section": "Data Split",
    "text": "Data Split\n\ndata_split <- initial_split(symptoms_fit, prop = 3/4) # 75% of data goes into training set\n\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-1-fitting-all-variables-to-predict-nausea",
    "href": "fluanalysis/code/modeleval.html#model-1-fitting-all-variables-to-predict-nausea",
    "title": "Model Evaluation",
    "section": "Model 1 fitting: all variables to predict nausea",
    "text": "Model 1 fitting: all variables to predict nausea\n\nDefine the model: logistic regression\n\nlog_mod <- logistic_reg() %>% #model type is logistic regression \n  set_engine(\"glm\") #engine set to generalized linear model\n\nI am using a logistic regression here because the outcome of interest (Nausea Y/N) is categorical\n\n\nCreate recipe\n\nrecipe_nausea <- recipe(Nausea ~., data = train_data)\n\nNausea is the outcome and all other variables are predictors\n\n\nCreate workflow: combine model definition and recipe\n\nnausea_log_wf <- workflow() %>% \n  add_model(log_mod) %>% #model definition \n  add_recipe(recipe_nausea) #model recipe\n\nThis will run a logistic regression on the flu data, predicting nausea using all other variables that we kept.\n\n\nModel fitting\n\nset.seed(626)\nnausea_fit <- nausea_log_wf %>% \n  fit(data = train_data)\n\nnausea_fit %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)            0.386      9.31     0.0414  0.967 \n 2 SwollenLymphNodesYes  -0.0795     0.230   -0.346   0.729 \n 3 ChestCongestionYes     0.110      0.249    0.440   0.660 \n 4 ChillsSweatsYes        0.743      0.369    2.02    0.0438\n 5 NasalCongestionYes     0.344      0.300    1.14    0.252 \n 6 CoughYNYes            -0.206      0.613   -0.336   0.737 \n 7 SneezeYes              0.217      0.254    0.855   0.393 \n 8 FatigueYes             0.157      0.423    0.371   0.711 \n 9 SubjectiveFeverYes    -0.157      0.272   -0.579   0.563 \n10 HeadacheYes            0.272      0.333    0.814   0.415 \n# … with 28 more rows\n\n\n\n\nModel assessment on training data: ROC curve\n\nset.seed(626)\nnausea_aug_test <- augment(nausea_fit, train_data)\n\nnausea_aug_test %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.782\n\n\nROC-AUC is ok\n\n\nModel assessment on testing data: ROC curve\n\nset.seed(626)\nnausea_fit_test <- nausea_log_wf %>% \n  fit(data = test_data)\n\nnausea_fit_test %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           -10.6      18.7      -0.566 0.571  \n 2 SwollenLymphNodesYes   -1.07      0.481    -2.22  0.0263 \n 3 ChestCongestionYes      0.779     0.504     1.55  0.122  \n 4 ChillsSweatsYes        -0.685     0.608    -1.13  0.260  \n 5 NasalCongestionYes      0.592     0.573     1.03  0.301  \n 6 CoughYNYes             -0.310     1.05     -0.294 0.769  \n 7 SneezeYes               0.478     0.458     1.04  0.297  \n 8 FatigueYes              0.223     1.08      0.208 0.835  \n 9 SubjectiveFeverYes      1.72      0.556     3.10  0.00195\n10 HeadacheYes             0.542     0.688     0.788 0.430  \n# … with 28 more rows\n\nnausea_aug_test2 <- augment(nausea_fit_test, test_data)\n\nnausea_aug_test2 %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.836\n\n\nThe testing data out-performed the training set"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-2-fitting-runny-nose-to-predict-nausea",
    "href": "fluanalysis/code/modeleval.html#model-2-fitting-runny-nose-to-predict-nausea",
    "title": "Model Evaluation",
    "section": "Model 2 fitting: runny nose to predict nausea",
    "text": "Model 2 fitting: runny nose to predict nausea\n\nCreate new recipe and workflow\n\nrecipe_nausea2 <- recipe(Nausea ~RunnyNose, data = train_data) #only include runny nose\n\nnausea_log_wf2 <- workflow() %>% \n  add_model(log_mod) %>% #model definition, use the same as Model 1\n  add_recipe(recipe_nausea2) #model recipe\n\n\n\nModel fitting\n\nset.seed(626)\nnausea_fit2 <- nausea_log_wf2 %>% \n  fit(data = train_data)\n\nnausea_fit2 %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic    p.value\n  <chr>           <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)   -0.738      0.165    -4.46  0.00000806\n2 RunnyNoseYes   0.0961     0.198     0.487 0.626     \n\n\n\n\nModel assessment on training data\n\nset.seed(626)\nnausea_aug_test2 <- augment(nausea_fit2, train_data)\n\nnausea_aug_test2 %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.510\n\n\nThe ROC-AUC here is lower than Model 1\n\n\nModel assessment on testing data\n\nset.seed(626)\nnausea_fit_test3 <- nausea_log_wf2 %>% \n  fit(data = test_data)\n\nnausea_fit_test3 %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    -0.368     0.307    -1.20    0.230\n2 RunnyNoseYes   -0.147     0.353    -0.416   0.677\n\nnausea_aug_test3 <- augment(nausea_fit_test3, test_data)\n\nnausea_aug_test3 %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test3 %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.514\n\n\nThe testing data is no different. Runny nose is likely not a good predictor of nausea."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-3-fitting-all-variables-to-predict-body-temperature",
    "href": "fluanalysis/code/modeleval.html#model-3-fitting-all-variables-to-predict-body-temperature",
    "title": "Model Evaluation",
    "section": "Model 3 fitting: all variables to predict Body Temperature",
    "text": "Model 3 fitting: all variables to predict Body Temperature\n\nDefine the model: linear regression\n\nlin_mod <- linear_reg() %>% #model type is linear regression \n  set_engine(\"lm\") #engine set to  linear model\n\n\n\nCreate recipe for Multivariate model\n\nrecipe_bt_all <- recipe(BodyTemp ~., data = train_data)\n\nBody Temp is the outcome and all other variables are predictors\n\n\nCreate workflow: combine model definition and recipe\n\nbt_lin_wf_all <- workflow() %>% \n  add_model(lin_mod) %>% #model definition \n  add_recipe(recipe_bt_all) #model recipe\n\nThis will run a linear regression on the flu data, predicting body temperature using all other variables that we kept.\n\n\nMultivariate Model Fitting\n\nbt_fit_all <- bt_lin_wf_all %>% \n  fit(data = train_data)\n\nbt_fit_all %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           97.9        0.354   277.    0        \n 2 SwollenLymphNodesYes  -0.204      0.108    -1.89  0.0599   \n 3 ChestCongestionYes     0.0863     0.114     0.759 0.448    \n 4 ChillsSweatsYes        0.100      0.158     0.637 0.525    \n 5 NasalCongestionYes    -0.376      0.134    -2.81  0.00517  \n 6 CoughYNYes             0.459      0.291     1.58  0.115    \n 7 SneezeYes             -0.470      0.117    -4.02  0.0000658\n 8 FatigueYes             0.424      0.181     2.35  0.0191   \n 9 SubjectiveFeverYes     0.488      0.125     3.89  0.000112 \n10 HeadacheYes            0.0343     0.146     0.235 0.815    \n# … with 28 more rows\n\n\n\n\nModel assessment on training data: RMSE and Rsq\n\nset.seed(626)\nbt_aug_train_all <- augment(bt_fit_all, train_data) #pull in train data\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n### RMSE and R2 to test model performance\n\nrmse1 <- bt_aug_train_all %>% rmse(truth = BodyTemp, .pred) #RMSE\nrsq1 <- bt_aug_train_all %>% rsq(truth = BodyTemp, .pred) #RSQ\nbt_metrics_all_train<- full_join(rmse1, rsq1)\n\nJoining with `by = join_by(.metric, .estimator, .estimate)`\n\nbt_metrics_all_train\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       1.12 \n2 rsq     standard       0.166\n\n\n\n\nModel assessment on testing data: RMSE and Rsq\n\nset.seed(626)\nbt_fit_test_all <- bt_lin_wf_all %>% \n  fit(data = test_data) #pull in test data\n\nbt_fit_test_all %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           98.7        0.655   151.    6.80e-164\n 2 SwollenLymphNodesYes  -0.0195     0.186    -0.105 9.17e-  1\n 3 ChestCongestionYes     0.297      0.205     1.45  1.49e-  1\n 4 ChillsSweatsYes        0.279      0.233     1.20  2.34e-  1\n 5 NasalCongestionYes     0.0556     0.229     0.243 8.09e-  1\n 6 CoughYNYes            -0.210      0.427    -0.491 6.24e-  1\n 7 SneezeYes             -0.175      0.193    -0.906 3.66e-  1\n 8 FatigueYes            -0.527      0.411    -1.28  2.02e-  1\n 9 SubjectiveFeverYes     0.266      0.195     1.37  1.74e-  1\n10 HeadacheYes            0.128      0.263     0.487 6.27e-  1\n# … with 28 more rows\n\nbt_aug_test_all <- augment(bt_fit_test_all, test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n### RMSE and R2 to test model performance\n\nrmse2 <- bt_aug_test_all %>% rmse(truth = BodyTemp, .pred) #RMSE\nrsq2 <- bt_aug_test_all %>% rsq(truth = BodyTemp, .pred) #RSQ\nbt_metrics_all_test<- full_join(rmse2, rsq2)\n\nJoining with `by = join_by(.metric, .estimator, .estimate)`\n\nbt_metrics_all_test\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.950\n2 rsq     standard       0.223\n\n\nHere it looks like the test data outperformed the model data (lower rmse and higher rsq)."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-4-fitting-runny-nose-to-predict-body-temperature",
    "href": "fluanalysis/code/modeleval.html#model-4-fitting-runny-nose-to-predict-body-temperature",
    "title": "Model Evaluation",
    "section": "Model 4 fitting: runny nose to predict Body Temperature",
    "text": "Model 4 fitting: runny nose to predict Body Temperature\n\nCreate new recipe and workflow\n\nrecipe_bt2 <- recipe(BodyTemp ~RunnyNose, data = train_data) #only include runny nose\n\nbt_lin_wf2 <- workflow() %>% \n  add_model(lin_mod) %>% #model definition, use the same as Model 1\n  add_recipe(recipe_bt2) #model recipe\n\n\n\nModel fitting\n\nbt_fit2 <- bt_lin_wf2 %>% \n  fit(data = train_data)\n\nbt_fit2 %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.2      0.0947   1048.   0      \n2 RunnyNoseYes   -0.318    0.114      -2.80 0.00537\n\n\n\n\nModel assessment on training data\n\nset.seed(626)\nbt_aug_train_uni <- augment(bt_fit2, train_data) #Train Data\n\n### RMSE and R2 to test model performance\n\nrmse3 <- bt_aug_train_uni %>% rmse(truth = BodyTemp, .pred) #RMSE\nrsq3 <- bt_aug_train_uni %>% rsq(truth = BodyTemp, .pred) #RSQ\nbt_metrics_uni_train<- full_join(rmse3, rsq3)\n\nJoining with `by = join_by(.metric, .estimator, .estimate)`\n\nbt_metrics_uni_train\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      1.22  \n2 rsq     standard      0.0141\n\n\n\n\nModel assessment on testing data\n\nset.seed(626)\nbt_fit_test_uni <- bt_lin_wf2 %>% \n  fit(data = test_data)\n\nbt_fit_test_uni %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    99.0       0.163   607.    2.12e-301\n2 RunnyNoseYes   -0.172     0.187    -0.918 3.60e-  1\n\nbt_aug_test_uni <- augment(bt_fit_test_uni, test_data) #Test Data\n\n### RMSE and R2 to test model performance\n\nrmse4 <- bt_aug_test_uni %>% rmse(truth = BodyTemp, .pred) #RMSE\nrsq4 <- bt_aug_test_uni %>% rsq(truth = BodyTemp, .pred) #RSQ\nbt_metrics_uni_test<- full_join(rmse4, rsq4)\n\nJoining with `by = join_by(.metric, .estimator, .estimate)`\n\nbt_metrics_uni_test\n\n# A tibble: 2 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard     1.08   \n2 rsq     standard     0.00464\n\n\nHere, the training data outperformed the model data, but either way, it does not look like Runny nose is a good predictor of Body Temperature.\nUltimately, our multivariate linear regression provided better performance assessments, so there is more exploring to be done!"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html",
    "href": "fluanalysis/code/machinelearning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(rsample) #Data split\nlibrary(tidymodels)\nlibrary(rpart) #Model fit\nlibrary(ranger) #Model fit\nlibrary(glmnet) #Model fit\nlibrary(rpart.plot)  #viz of decision tree\nlibrary(vip) #viz of variable importance plots\nlibrary(ggpmisc) #for adding linear regression to plots"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#load-data",
    "href": "fluanalysis/code/machinelearning.html#load-data",
    "title": "Machine Learning",
    "section": "Load data",
    "text": "Load data\n\ndata <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#data-splitting",
    "href": "fluanalysis/code/machinelearning.html#data-splitting",
    "title": "Machine Learning",
    "section": "Data splitting",
    "text": "Data splitting\n\nset.seed(123)\n\ndata_split <- initial_split(\n  data, prop = 7/10, #70:30 Split\n  strata = BodyTemp) #more balanced outcomes across train/test split\n  \ntrain <- training(data_split)\ntest  <- testing(data_split)"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#create-recipes-for-later-use",
    "href": "fluanalysis/code/machinelearning.html#create-recipes-for-later-use",
    "title": "Machine Learning",
    "section": "Create recipes for later use",
    "text": "Create recipes for later use\n\n#Training data\nbt_rec_train <- recipe(BodyTemp~., data = train) %>% \n  step_dummy(all_nominal(), -all_outcomes()) %>% #pick nominal predictors\n  step_ordinalscore() %>%\n  step_zv(all_predictors()) \n\n#Testing data\nbt_rec_test <- recipe(BodyTemp~., data = test) %>% \n  step_dummy(all_nominal(), -all_outcomes()) %>% #pick nominal predictors\n  step_ordinalscore() %>%\n  step_zv(all_predictors())"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#lasso-model-tuning-and-fitting",
    "href": "fluanalysis/code/machinelearning.html#lasso-model-tuning-and-fitting",
    "title": "Machine Learning",
    "section": "LASSO model tuning and fitting",
    "text": "LASSO model tuning and fitting\n\nSpecify Model\n\nlasso_mod <- linear_reg(penalty = tune(), mixture = 1) %>% \n  set_engine(\"glmnet\")\n\nSetting mixture to a value of one means that the glmnet model will potentially remove irrelevant predictors and choose a simpler model.\n\n\nCreate Workflow\n\nlasso_wf <- workflow() %>%\n  add_model(lasso_mod) %>%\n  add_recipe(bt_rec_train)\n\n\n\nCreating a Tuning Grid\n\nlasso_grid <- tibble(penalty = 10^seq(-3, 0, length.out = 30))\n\n\n\nUse cross-validation for tuning\n\nlasso_resample <- lasso_wf %>%\n  tune_grid(resamples = fold_bt_train,\n            grid = lasso_grid,\n            control = control_grid(verbose = FALSE, save_pred = TRUE),\n            metrics = metric_set(rmse))\n\nlasso_resample %>%\n  collect_metrics()\n\n# A tibble: 30 × 7\n   penalty .metric .estimator  mean     n std_err .config              \n     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1 0.001   rmse    standard    1.17    25  0.0170 Preprocessor1_Model01\n 2 0.00127 rmse    standard    1.17    25  0.0170 Preprocessor1_Model02\n 3 0.00161 rmse    standard    1.17    25  0.0170 Preprocessor1_Model03\n 4 0.00204 rmse    standard    1.17    25  0.0170 Preprocessor1_Model04\n 5 0.00259 rmse    standard    1.17    25  0.0170 Preprocessor1_Model05\n 6 0.00329 rmse    standard    1.17    25  0.0169 Preprocessor1_Model06\n 7 0.00418 rmse    standard    1.17    25  0.0169 Preprocessor1_Model07\n 8 0.00530 rmse    standard    1.17    25  0.0168 Preprocessor1_Model08\n 9 0.00672 rmse    standard    1.16    25  0.0168 Preprocessor1_Model09\n10 0.00853 rmse    standard    1.16    25  0.0167 Preprocessor1_Model10\n# … with 20 more rows\n\n\n\n\nModel plotting\n\nlr_plot <- lasso_resample %>% \n  collect_metrics() %>% \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() +\n  scale_x_log10(labels = scales::label_number())\n\nlr_plot\n\n\n\n\n\n\nSelect the best model\n\n#Show best model\nlasso_resample %>% show_best(n=1)\n\n# A tibble: 1 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0452 rmse    standard    1.15    25  0.0162 Preprocessor1_Model17\n\n#Select best model\nbest_lasso <- lasso_resample %>%\n  select_best()\n\nLasso model RMSE: 1.18 (slightly better than Tree)\n\n\nCreate final fit based on best model\n\nlasso_final_wf <- lasso_wf %>% \n  finalize_workflow(best_lasso) #update workflow with best model\n\nlasso_final_fit <- lasso_final_wf %>%\n  fit(train) #fit updated workflow to training data\n\n\n\nEvaluate final fit\n\nCalculating residuals\n\nlasso_residuals <- lasso_final_fit %>%\n  augment(train) %>% #use augment() to make predictions from train data\n  select(c(.pred, BodyTemp)) %>%\n  mutate(.resid = BodyTemp - .pred) #calculate residuals and make new row.\n\nlasso_residuals\n\n# A tibble: 508 × 3\n   .pred BodyTemp .resid\n   <dbl>    <dbl>  <dbl>\n 1  98.7     97.8 -0.913\n 2  98.8     98.1 -0.705\n 3  98.5     98.1 -0.391\n 4  98.8     98.2 -0.637\n 5  98.7     97.8 -0.947\n 6  98.6     98.2 -0.401\n 7  98.2     98.1 -0.147\n 8  99.3     98   -1.28 \n 9  98.8     97.7 -1.11 \n10  99.0     98.2 -0.790\n# … with 498 more rows\n\n\n\n\nPlot predictions vs. true value\n\nlasso_pred_plot <- ggplot(lasso_residuals, \n                          aes(x = BodyTemp, \n                              y = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Actual: LASSO\", \n       x = \"Body Temperature Outcome\", \n       y = \"Body Temperature Prediction\") +\n  stat_poly_line() +\n  stat_poly_eq()\nlasso_pred_plot\n\n\n\n\nRSQ is low but there is still a positive correlation there (which is good)\n\n\nPlot residuals vs. predictions\n\nlasso_residual_plot <- ggplot(lasso_residuals, \n                              aes(y = .resid, \n                                  x = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Residuals: LASSO\", \n       x = \"Body Temperature Prediction\", \n       y = \"Residuals\") +\n   stat_poly_line() +\n  stat_poly_eq()\nplot(lasso_residual_plot) #view plot\n\n\n\n\nThere should be no relationship here, which there isn’t."
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#random-forest-model-tuning-and-fitting",
    "href": "fluanalysis/code/machinelearning.html#random-forest-model-tuning-and-fitting",
    "title": "Machine Learning",
    "section": "Random Forest model tuning and fitting",
    "text": "Random Forest model tuning and fitting\n\nDetect cores for RFM computation\n\ncores <- parallel::detectCores()\ncores\n\n[1] 4\n\n\n\n\nSpecify Model\n\nrf_mod <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n  set_engine(\"ranger\", num.threads = cores) %>% \n  set_mode(\"regression\")\n\n\n\nCreate workflow\n\nrf_wf <- workflow() %>% add_model(rf_mod) %>%\n  add_recipe(bt_rec_train)\n\n\n\nCreate grid for model tuning\n\nrf_grid  <- expand.grid(mtry = c(3, 4, 5, 6),\n                        min_n = c(40,50,60), \n                        trees = c(500,1000))\n\n\n\nUse cross-validation for tuning\n\nrf_resample <- rf_wf %>% \n  tune_grid(fold_bt_train,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(rmse))\n\n\nCheck CV metrics\n\nrf_resample %>%\n  collect_metrics()\n\n# A tibble: 25 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     8    38 rmse    standard    1.16    25  0.0160 Preprocessor1_Model01\n 2    29    14 rmse    standard    1.20    25  0.0162 Preprocessor1_Model02\n 3    24     2 rmse    standard    1.22    25  0.0158 Preprocessor1_Model03\n 4    15    31 rmse    standard    1.17    25  0.0160 Preprocessor1_Model04\n 5     7    32 rmse    standard    1.16    25  0.0164 Preprocessor1_Model05\n 6    20     9 rmse    standard    1.20    25  0.0159 Preprocessor1_Model06\n 7    13     7 rmse    standard    1.19    25  0.0163 Preprocessor1_Model07\n 8     2    15 rmse    standard    1.17    25  0.0164 Preprocessor1_Model08\n 9    23    28 rmse    standard    1.18    25  0.0161 Preprocessor1_Model09\n10    23     4 rmse    standard    1.22    25  0.0158 Preprocessor1_Model10\n# … with 15 more rows\n\n\n\n\n\nModel performance plotting\n\nrf_resample %>% autoplot()\n\n\n\n\n\n\nSelect the best model\n\n#Show best model\nrf_resample %>%\n  show_best(n=1)\n\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     8    38 rmse    standard    1.16    25  0.0160 Preprocessor1_Model01\n\n#Select best model\nbest_rf <- rf_resample %>%\n  select_best(method = \"rmse\")\n\nRandom forest model RMSE: 1.20\n\n\nCreate final fit based on best model\n\nrf_final_wf <- \n  rf_wf %>% \n  finalize_workflow(best_rf) #update workflow with best model\n\nrf_final_fit <- \n  rf_final_wf %>%\n  fit(train) #fit best model to training data\n\n\n\nEvaluate final fit\n\nCalculating residuals\n\nrf_residuals <- rf_final_fit %>%\n  augment(train) %>% #use augment() to make predictions from train data\n  select(c(.pred, BodyTemp)) %>%\n  mutate(.resid = BodyTemp - .pred) #calculate residuals and make new row.\n\nrf_residuals\n\n# A tibble: 508 × 3\n   .pred BodyTemp .resid\n   <dbl>    <dbl>  <dbl>\n 1  98.7     97.8 -0.854\n 2  98.6     98.1 -0.513\n 3  98.7     98.1 -0.643\n 4  98.7     98.2 -0.535\n 5  98.8     97.8 -1.02 \n 6  98.5     98.2 -0.336\n 7  98.3     98.1 -0.218\n 8  99.1     98   -1.12 \n 9  98.8     97.7 -1.07 \n10  98.8     98.2 -0.644\n# … with 498 more rows\n\n\n\n\nPlot predictions vs. true value\n\nrf_pred_plot <- ggplot(rf_residuals, \n                          aes(x = BodyTemp, \n                              y = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Actual: Random Forest\", \n       x = \"Body Temperature Actual\", \n       y = \"Body Temperature Prediction\") +\n   stat_poly_line() +\n  stat_poly_eq()\nrf_pred_plot\n\n\n\n\nThere is a stronger correlation here than in the LASSO or Tree Model\n\n\nPlot residuals vs. predictions\n\nrf_residual_plot <- ggplot(rf_residuals, \n                              aes(y = .resid, \n                                  x = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Residuals: Random Forest\", \n       x = \"Body Temperature Prediction\", \n       y = \"Residuals\") +\n   stat_poly_line() +\n  stat_poly_eq()\nplot(rf_residual_plot) #view plot\n\n\n\n\nThere is a slight correlation here, which is not ideal."
  },
  {
    "objectID": "tidytuesday_exercise2.html",
    "href": "tidytuesday_exercise2.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "In this exercise, I will analyze the Tidy Tuesday data from the week of April 11, 2023. The data comes from the Humane League’s US Egg Production dataset, which is based on USDA reports of cage-free egg supply from 2007 to 2021."
  },
  {
    "objectID": "tidytuesday_exercise2.html#remove-unnecessary-variables-and-observations",
    "href": "tidytuesday_exercise2.html#remove-unnecessary-variables-and-observations",
    "title": "Tidy Tuesday Exercise",
    "section": "Remove unnecessary variables and observations",
    "text": "Remove unnecessary variables and observations\n\n#For egg production data, keep all variables but source\n#Then remove observations that do not contain \"all\" in production process\n#Then remove observations that do not contain \"table egg\" in production type\neggprod_clean <- eggproduction %>% \n  select(!source) %>% \n  filter(prod_process == \"all\", prod_type == \"table eggs\")\n\n#For cage free percentage data, keep all variables but source\n#Since there are so many NAs in the percent eggs variable, I will also remove that variable since it is not going to be useful in analysis\n#Then remove data prior to 2016 since that is as far back as egg production data goes\ncagefree_clean <- cagefreepercentages %>% \n  select(!c(source, percent_eggs)) %>% \n  filter(observed_month >= \"2016-04-30\")"
  },
  {
    "objectID": "tidytuesday_exercise2.html#look-at-the-data-again",
    "href": "tidytuesday_exercise2.html#look-at-the-data-again",
    "title": "Tidy Tuesday Exercise",
    "section": "Look at the data again",
    "text": "Look at the data again\n\neggprod_clean %>% ggplot(aes(observed_month, log10(n_eggs))) +\n  geom_point() +\n  geom_line()\n\n\n\n\nNow that we have cleaned the data by:\n\nRemoving unnecessary variables\nSubsetting the production product to “all”\nSubsetting the production type to “table eggs”\n\nWe can see a distinct upward trend in the production of table eggs since 2017. We can also see that there are certain months that the egg production drops, like in the early months of each year. Egg production rates also dropped significantly at the start of the COVID-19 pandemic (summer 2020).\n\ncagefree_clean %>% ggplot(aes(observed_month, percent_hens)) +\n  geom_point() +\n  geom_line()\n\n\n\n\nThere is a distinct upward trend in the percentage of cage free hens, rising from 10% to 30% from 2017 to 2021"
  }
]